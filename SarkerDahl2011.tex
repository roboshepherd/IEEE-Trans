% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[journal]{IEEEtran}
%%%
\usepackage[nolist]{acronym}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage[colorlinks=false]{hyperref}
\usepackage{hypernat,subfig}
\usepackage{geometry}
\usepackage{color}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{rotating}
\usepackage{listings,program}
\usepackage{algorithmicx,algpseudocode}
\newcommand{\HRule}{\rule{\linewidth}{0.3mm}} 
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[journal]{../sty/IEEEtran}
\usepackage{cite}
% *** GRAPHICS RELATED PACKAGES ***
%
%\ifCLASSINFOpdf
  \usepackage{graphicx}
  \graphicspath{{../RAS-Draft/}{../RAS-Draft/images/}}
  %\usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
%\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
 %  \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  %  \DeclareGraphicsExtensions{.eps}
%\fi
% *** MATH PACKAGES ***
%\usepackage[cmex10]{amsmath}
%\usepackage{algorithmic}
%\usepackage{array}
%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on 
%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
%\usepackage[tight,footnotesize]{subfigure}
%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
\usepackage{fixltx2e}
\usepackage{stfloats}
\usepackage{url}
% correct bad hyphenation here
%\hyphenation{op-tical net-works semi-conduc-tor}
%==================================================================
\begin{document}
%
\begin{acronym}
%==== A B C D ====
\acro{AFM}{attractive field model}
\acro{AGV}{automated guided vehicle}
\acro{APCD}{average production completion delay}
\acro{APMW}{average pending maintenance work-load}
%\acro{AS}{active space}
\acro{BMS}{biology-inspired manufacturing system}
\acro{CCD}{charge-coupled device}
%\acro{CCM}{centralized communication mode}
\acro{DEM}{data and event management}
\acro{DOL}{division of labour}
%==== E F G H ====
%\acro{EPSRC}{Engineering and Physical Sciences Research Council}
\acro{GigE}{Gigabyte Ethernet}
\acro{GIL}{Global Interpreter Lock}
%\acro{GPS}{global positioning system}	
\acro{GSNC}{global sensing - no communication}
%\acro{GUI}{graphical user interface}
\acro{HEAD}{hybrid event-driven architecture on D-Bus}
%====  I J K L ====
%\acro{IF}{independent founders}
%\acro{INS}{indoor navigation system}
\acro{IPC}{inter-process communication}
%\acro{IR}{infrared}
%\acro{LCM}{local communication mode}
\acro{LSLC}{local sensing - local communication}
%==== M N O P ====
\acro{MOM}{maintenance only mode}
\acro{MRS}{multi-robot system}
\acro{MRTA}{multi-robot task allocation}
\acro{P2P}{peer-to-peer}
%\acro{PF}{potential field}
\acro{PMM}{production and maintenance mode}
%=====  Q R S T ====
\acro{RCC}{robot-controller client}
%\acro{RW}{random walk}
\acro{SDK}{software-development kit}
%\acro{SF}{swarm founders}
\acro{SHM}{shared memory}
%\acro{SI}{swam intelligence}
%\acro{SO}{self-organization}
%\acro{SR}{self-regulation}
%\acro{SRS}{swarm robotic system}
\acro{TPS}{task perception server}
%==== U V W X ====
%==== Y Z ==== 
\end{acronym}
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Self-organized Multi-robot Task~Allocation using Attractive Filed Model: A Taxonomy and Comparison of Centralized and Local Communication}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
\author{Md Omar Faruque Sarker
        and~Torbj{\o}rn S. Dahl
}
        %and{Life~Fellow,~IEEE}% <-this % stops a space
\thanks{M. O. F. Sarker and T. S. Dahl is with Cognitive Robotics Research Centre,
University of Wales, Newport,
Newport Business School,
Allt-yr-yn Campus %Allt-yr-yn Avenue\\
Newport, NP20 5DA,
United Kingdom. e-mail: Mdomarfaruque.Sarker@newport.ac.uk}% <-this % stops a space
%\thanks{J. Doe and J. Doe are with Anonymous University.}% <-this % stops a space
%\thanks{Manuscript received April 19, 2005; revised January 11, 2007.}}

% note the % following the last \IEEEmembership and also \thanks - 
% these prevent an unwanted space from occurring between the last author name
% and the end of the author line. i.e., if you had this:
% 
% \author{....lastname \thanks{...} \thanks{...} }
%                     ^------------^------------^----Do not want these spaces!
%
% a space would be appended to the last name and could cause every name on that
% line to be shifted left slightly. This is one of those "LaTeX things". For
% instance, "\textbf{A} \textbf{B}" will typeset as "A B" not "AB". To get
% "AB" then you have to do: "\textbf{A}\textbf{B}"
% \thanks is no different in this regard, so shield the last } of each \thanks
% that ends a line with a % and do not let a space in before the next \thanks.
% Spaces after \IEEEmembership other than the last one are OK (and needed) as
% you are supposed to have spaces between the names. For what it is worth,
% this is a minor point as most people would not even notice if the said evil
% space somehow managed to creep in.
% The paper headers
%\markboth{Journal of \LaTeX\ Class Files,~Vol.~6, No.~1, January~2007}%
%{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
% 
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.
% If you want to put a publisher's ID mark on the page you can do it like
% this:
%\IEEEpubid{0000--0000/00\$00.00~\copyright~2007 IEEE}
% Remember, if you use this you must call \IEEEpubidadjcol in the second
% column for its text to clear the IEEEpubid mark.
% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}
% make the title area
\maketitle
\begin{abstract}
This paper proposes to solve multi-robot task-allocation (MRTA) problems using a set of previously published generic rules for self-organised division of labour derived from the observation of ant, human and robotic social systems. The concrete form of these rules, the \textit{attractive filed model} (AFM), are sufficiently abstraction to accommodate different sensing and communication models. We have validated the effectiveness of AFM for MRTA using two bio-inspired communication and sensing strategies: \textit{global sensing - no communication} and \textit{local sensing - local communication}. The former is realized using a centralized communication system and the latter is emulated as a peer-to-peer local communication scheme. Both strategies are evaluated using 16 e-puck robots.
\end{abstract}
% IEEEtran.cls defaults to using nonbold math in the Abstract.
% This preserves the distinction between vectors and scalars. However,
% if the journal you are submitting to favors bold math in the abstract,
% then you can use LaTeX's standard command \boldmath at the very start
% of the abstract to achieve this. Many IEEE journals frown on math
% in the abstract anyway.

% Note that keywords are not normally used for peerreview papers.
%\begin{IEEEkeywords}
%IEEEtran, journal, \LaTeX, paper, template.
%\end{IEEEkeywords}
% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
%\IEEEpeerreviewmaketitle
\section{Introduction}
% The very first letter is a 2 line initial drop letter followed
% by the rest of the first word in caps.
% 
% form to use if the first word consists of a single letter:
% \IEEEPARstart{A}{demo} file is ....
% 
% form to use if you need the single drop letter followed by
% normal text (unknown if ever used by IEEE):
% \IEEEPARstart{A}{}demo file is ....
% 
% Some journals put the first two words in caps:
% \IEEEPARstart{T}{his demo} file is ....
% 
% Here we have the typical use of a "T" for an initial drop letter
% and "HIS" in caps to complete the first word.
\IEEEPARstart{M}{ulti-robot}
 systems can provide high levels of performance, fault-tolerance and robustness in complex and distributed tasks through parallelism and redundancy \cite{Arkin1998,Parker+2006}. % However, in order to get the potential benefits of \aclp{MRS}, we need to answer a common research question.
 \textit{But how can we allocate the tasks among robots?} Traditionally, this issue has been identified as \acfi{MRTA} \cite{Gerkey+2004}, analogous to \acfi{DOL} in biological and human social systems \cite{Sendova-Franks+1999}.
%\footnote{Although the term ``division of labour'' is often used in biological literature and the term 'task-allocation' is primarily used in multi-agent literature.  In this paper we have used these terms interchangeably.} 

MRTA is generally defined as the problem of assigning tasks in an appropriate time to the appropriate robots considering the changes in task-requirements, team-performance and the environment \cite{Gerkey+2003}. %This is an {\em NP-hard} optimal assignment problem where optimal solutions can not be found quickly for large and complex problems \cite{Parker2008}.  
The complexities of the {\em distributed} MRTA problem arise from the fact that there is no central planner or coordinator for task assignments, and in a large \acl{MRS}, robots are generally limited to local sensing, communication and to interaction. %No robot has complete knowledge of the past, present or future actions of the other robots.


%Self-organized task-allocation approaches, on the other hand, rely on emergent group behaviours, such as emergent cooperation \cite{Kube+1993}, adaptation rules \cite{Liu+2007} and similar mechanisms. They are generally more robust and scale better to large team sizes. However, emergent or self-organized task-allocation is difficult to design, to analyse formally and to implement in real robots. The solutions from self-organized systems are also commonly sub-optimal and it is very difficult to predict the exact behaviours of robots and the overall system performance.

Within the context of the Engineering and Physical Sciences Research Council (EPSRC) project, 'Defying the Rules: How Self-regulatory Systems Work', we have presented the attractive field model (AFM) \cite{Arcaute+2008}, a model of self-regulated DOL  informed by studies of self-regulated task-allocation in ant and human social systems. AFM suggests four generic rules to explain self-regulation in those social systems. These four rules are: \textit{continuous flow of information}, \textit{concurrency}, \textit{learning} and \textit{forgetting}.  All of them are explained below. Primarily, these rules enable the derivation of local control laws for regulating an individual's task-allocation behaviour in a way that facilitates DOL in the entire group.

In biological social systems, communications among the group members, as well as the perception of tasks, are two key components of self-organized DOL. In robotics, existing self-organized task-allocation methods rely heavily upon local sensing and local communication between individuals. AFM however, differs significantly in this point.  Being a highly abstract model, it avoids a strong dependence on any specific communication strategy such as the local communications and interactions found in many existing approaches to MRTA. AFM uses the abstraction of attractive fields or continuous flows of information from tasks to agents.  This flow of information can be realized by through either centralized or decentralized communication strategies under explicit and implicit communication modes.

In order to enable continuous flow of information in our \acl{MRS}, we have implemented two types of sensing and communication strategies inspired by the self-regulated DOL found in two types of social wasps: {\em polistes} and {\em polybia} \cite{Jeanne1999}. Depending on the group size, these species follow different strategies for communication and sensing of tasks. Polistes wasps are called {\em independent founders}.  In this species reproductive females establish colonies alone or in small groups (in the order of $10^2$), but independent of any sterile workers.  Polybia wasps, on the other hand, are called {\em swarm founders} where a swarm of workers and queens initiate colonies consisting of several hundreds to millions of individuals.  

The most notable difference in the organization of work in these two social wasps is that independent founders do not rely on any cooperative task performance while swarm founders interact with each-other locally to accomplish their tasks.  The work mode of independent founders can be considered as {\em global sensing - no communication (GSNC)} where the individuals sense the task requirements throughout a small colony and do these tasks without communicating with each other.  The work mode of the swarm founders, on the other hand, can be treated as {\em local sensing - local communication (LSLC)} where the individuals can only sense tasks locally due to the large colony size and can communicate locally to exchange information, e.g. task-requirements (although their exact communication mechanism is unknown).  In the study presented here, we have compare the performance of these two sensing and communication strategies for self-regulated DOL in robots under AFM. 

The main contributions of this paper are as follows.
%\begin{itemize}
This study compares the performance of two bio-inspired sensing and communication strategies in producing self-regulated MRTA.
A flexible multi-robot control architecture has been developed adopting D-Bus inter-process communication technology. A novel taxonomy of MRTA solutions has been derived based on organization of task-allocation, interaction and communication.
%\end{itemize}

This paper has been organized as follows.
Section~2 reviews the related literature on MRTA.
Section~3 presents the new taxonomy of MRTA solutions.
Section~4 presents AFM based task-allocation solution for multi-robot systems. 
Section~5  describes our centralized and local communication schemes used in this study.
Section~6 and Section~7 present the design and implementation of our experiments respectively.
Section~8 describes our results. 
Section~9 discusses the performance of self-regulated MRTA under both centralized and local communication strategies.
Section~10 draws conclusions and presents possibilities for future work.
\section{Related work}
\label{sec:rw}
%\begin{figure*}
%\centering
%\includegraphics[width=0.7\linewidth, angle=0]
%{ta-categories.eps}
%\caption{Classification of MRTA solutions.}
%\label{fig:mrta-classification} % Give a unique label
%\end{figure*}
%%
Since the 90s, many robot control architectures have been designed with thed sole purpose of addressing the MRTA issue from different perspectives. Based on the high-level design of those solutions, we have classified them into two categories: i) {\em predefined} or {\em explicit} task-allocation and ii) {\em bio-inspired self-organized} task-allocation. %Fig. \ref{fig:mrta-classification} illustrates our classification.

%In most of the traditional multi-robot systems, task allocation is achieved using well-defined models of tasks and environments. Here it is assumed that the system designer has precise knowledge of tasks and robot-capabilities. Knowledge-based and multi-agent based approaches use various knowledge-based techniques to represent tasks and robot-capabilities. An early well-known MRTA architecture of this category is ALLIANCE in which each robot models the ability of team-members to perform tasks by observing their current task performances and collecting relevant task quality statistics \cite{Parker1998}. %Multi-agent systems also use both centralized and decentralized approaches for allocating tasks among  its  peers. A detailed categorization has been reported in by \cite{Shen+2001} where in a multi-agent task allocation systems are divided into those that use a central supervising agent , those that use a few mediator agents and those that use all independent agents. 
Early research on explicit task-allocation was dominated by explicit cooperation \cite{Parker2008}, use of dynamic role assignment \cite{Chaimowicz2002} and market-based bidding approach \cite{Dias+2006}. When taking these approaches, robots perform explicit task-allocation activities, commonly including communication with other group members for negotiating tasks. These approaches are intuitive and comparatively straight forward to design and implement and can be analysed formally. However, these approaches typically work well only when the number of robots are small ($\leq 10$) \cite{Lerman+2006}.
%%
%As a feasible alternative to the above multi-agent based task-allocation mechanisms, many researchers have been following the market-based approaches \cite{Dias+2006}.  These approaches originated from the Contract-Net Protocol.  Market-based approaches can be implemented as a centralized auctioning system  as a set of a few auctioneers or as all independent auctioneers.
%Under role or value-based task-allocation schemes, each role assumes several specific tasks and each robot selects roles that best suit their individual skills and capabilities \cite{Chaimowicz2002}. In this case, robots are typically heterogeneous, each one having variety of different sensing, computation and effector capabilities. In multi-robot soccer \cite{Stone+1999}, positions played by different robots are often defined as roles, e.g. goal-keeper, left/right defender and left/right forward. 
%Under control-theoretic approaches, a model of the system is usually developed, that converts the task specification into an objective function to be optimized. This model typically uses the rigid body dynamics of the robots and requires that the mass and other parameters are well-known. Control laws for individual robots are derived either analytically either in advance or at run-time.
%Unlike most other approaches where task-allocation problem is taken as discrete, control-theoretic approaches can produce continuous  solutions. The formalisms of these systems allow system designer to check the system's controllability, stability and related other properties.  These systems typically use some degree of centralization, e.g. choosing a leader robot.  
%Control-theoretic approaches have been developed for multi-robot formation control \cite{Belta+2004} and multi-robot box-pushing \cite{Pereira+2003}.
%Predefined task-allocation through other approaches are also present in the literature. For example, inspired by the vacancy chain phenomena in nature, a vacancy chain scheduling algorithm has been applied to a restricted class of MRTA problems in spatially classifiable domains \cite{Dahl+2004}.

Task performance in self-organized approaches relies on the collective behaviours resulting from the local interactions of many simple and mostly homogeneous or interchangeable agents. Robots choose their tasks independently using general principles of self-organization such as: positive and negative feedback, multiple interactions among entities and their environment, and randomness or amplification of fluctuations \cite{Camazine+2001}. Moreover. interaction among individuals and their environment can be modulated by stigmergic, local and global communications.  Among many variants of self-organized task-allocation mechanisms, the most common type is threshold-based task-allocation \cite{Bonabeau+1999}. In this approach, a robot's decision to select a particular task depends largely on its perception of a stimulus, e.g., the demand for a task to be performed, and its corresponding response threshold for that task.

Under the deterministic response-threshold approach, each robot has an activation threshold for each task that needs to be performed. It continuously perceives or monitors the stimulus of all tasks that reflect the relative urgencies of tasks. When a particular task-stimulus exceeds a predefined threshold the robot starts working on that task, typically reducing thie related stimuli. When the task-stimuli falls below the fixed threshold the robot abandons that task. This type of approach has been effectively applied in foraging \cite{Liu+2007,Krieger+2000} and aggregation \cite{Agassounon+2002}. The fixed response threshold can initially be same for all robots \cite{Jones+2000} or they can be different according robot capabilities or the configuration of the system \cite{Krieger+2000}. Adaptive response-threshold models change the thresholds over time.  A robot's response threshold for a given task is often decreased as a result of the robot performing that task.  This enables a robot to select that particular task more frequently or in other words specialise on that task \cite{Bonabeau+1999,Agassounon+2002}.

Unlike the deterministic approach, where robots respond preditably, e.g., to the task stimulus that is the furthest above its threshold, probabilistic or stochastic approaches offer a selection process based-on a probability distribution over the tasks.  In this case, all tasks commonly have at least a small, non-zero probability of being chosen.  This random element typically prevents starvation of low=stimulus tasks.
%%
%Explicit task-allocation mechanisms require a known or controlled environment where it is possible to model the tasks, the robots and the environment.  Note that here, tasks can be arbitrarily complex and often require a high level of sensory and processing abilities in the robots.  Robot teams can consists of homogeneous or heterogeneous individuals, having different capabilities based on the variations in their hardware or software, but the uncertainty of the environment is reduced to a minimum. 

Bio-inspired, self-organized MRTA mechanisms rely to a much smaller degree on modelling the environment, tasks or robot capabilities.  Most existing research in this area considers a single global task e.g. foraging, area cleaning and box-pushing with the focus of the work being the design of individual robot controllers that can accomplish the task \cite{Gerkey+2003}. More research is needed to study the performance of the self-organized approach in handling several different tasks. %At this moment, the bottom line remains as ``select simple robots for simple tasks (self-organized approach) and complex robots for complex tasks (predefined approach)''.

Both of the above task-allocation approaches expose their relative strengths and weaknesses when they are put under real-time experiments with variable number of robots and tasks. In an arbitrary event handling domain, a comparison between self-organized and predefined market-based task-allocation was reported by Kalra and Martinoli \cite{kalra+2007}.  They found that explicit task-allocation was more efficient when the required information could be captured accurately.  The threshold-based approach offered similar quality of allocation at a fraction of cost in noisy environment.  

Gerkey and Mataric have presented a study \cite{Gerkey+2003} that compared the complexity and performance of key architectures, including ALLIANCE \cite{Parker1998}, the Broadcast of local eligibillity (BLE) arcgutecture \cite{Werger2001}, M+ \cite{Botelho+1999}, MURDOCH \cite{Gerkey+2002}, First piece auctions \cite{Zlot+2002} and Dynamic role assignment \cite{Chaimowicz2002}.  All of these rely on explicit task-allocation mechanisms. The computational and communication requirements of these MRTA systems were expressed as a function of the number of robots and tasks.  Although the study did not explicitly measure the scalability of the architectures, it clearly showed that many explicit task-allocation mechanisms fail to scale well in environments where the number of robots and tasks are large, given limited overall communication bandwidth and limited processing power for individual robots.
%=======================================================================
\section{A taxonomy of MRTA}
\label{sec:taxonomy}
In order to categorize both explicit and self-organized MRTA approaches we propose three distinct dimensions: i) organization of task-allocation, ii) degree of interaction and iii) degree of communication.  Fig. \ref{fig:mrta-complexities} depicts these dimensions.  This taxonomy can be used to measure the complexities involved in various kinds of MRTA problems and to facilcilitated the design of appropriate systems form handling them.
%%
\begin{figure*}[t]
\begin{minipage}[t]{0.48\linewidth}
\centering
\includegraphics[width=0.99\linewidth, angle=0]
{./images/taxonomy-ta-comm-OK.eps}
%figure caption is below the figure
\caption{Classification of MRTA solutions based on task-allocation and communication strategies}
\label{fig:taxonomy-ta-comm} % Give a unique label
\end{minipage}
%\end{figure}
%\begin{figure}[t]
\begin{minipage}[t]{0.48\linewidth}
\centering
\includegraphics[width=0.99\linewidth, angle=0]
{./images/taxonomy-comm-interaction-OK.eps}
%figure caption is below the figure
\caption{Information flow caused by different levels of communication and interaction}
\label{fig:taxonomy-comm-interaction} % Give a unique label
\end{minipage}
\end{figure*}
%%
In Fig. \ref{fig:mrta-complexities}, X axis represents the number of active nodes that provides the task-allocation to the group. For example, in any predefined  task-allocation approach, we can use one external centralized entity or one of the robots (aka leader) to manage the task-allocation. In many predefined methods, e.g. in market-based systems,  multiple nodes can act as mediators or task-allocators. Under predefined task-allocation approach,  a small number of robots can have fully distributed task-allocation where each robot acts as an independent task-allocator (e.g. as in ALLIANCE architecture).
%%%%
Most of the self-organized task-allocation methods are fully distributed, i.e. each robot selects its tasks independently and without the help of a leader.  However, robots might be dependent on other entities for getting the latest {\em information} about tasks.  Recent studies on swarm-robotic flocking by Celikkanat {\em et al.} \cite{Celikkanat+2008} show that a swarm can be guided to a target by a few informed individuals or leaders while the remaining robots remain self-organied.  Task-allocation in a swarm of robots through one central entity may be rare since one of the major motivations behind swarm robotic systems is to make more robust by avoiding single points of failure.
%%
%In Fig. \ref{fig:mrta-complexities}, the y-axis corresponds to the level of robot-robot interaction present in the system.  Parker has classified group-level interaction into {\em collective}, {\em cooperative}, {\em coordinative} and {\em collaborative} \cite{Parker2008}.  The presence of interaction can be due to the nature of the problem, e.g. cooperation is necessary in co-operative transport tasks. Alternately, this interaction can be a design choice where interaction can improves the performance of the team, e.g. cooperation in cleaning a work-site is not necessary but it can help to improve the  efficiency of this task. 
%Y axis can also be used to refer to the degree of coupling present in the system.  In case of collective interaction, robots merely co-exist, i.e.  they may not be aware of each other except treating others as obstacles. Many multi-robot systems are loosely-coupled where robots can indirectly infer some states of the environment from their team-mates' actions.  But in many cases, e.g. in  co-operative transport, robots not only recognize others as their team-mates, but also they coordinate their actions. Thus they form a  tightly coupled system. This level of interaction and coupling also gives us the information about potential side-effects of failure of an individual robot. Tightly coupled systems with high degrees of interactions among the robots  suffer from the performance loss if some of the robots removed from the system.
%The Z axis in Fig. \ref{fig:mrta-complexities} represents the communication overhead of the system. This can be the result of the interactions  of robots under a given task-allocation method. As we have discussed before various task-allocation methods rely upon variable degrees of robot-robot communications.  On the other hand, the communication capabilities of individual robots can limit (or expand) the level of interaction can be made  in a given group. Thus in one way, considering the interaction requirements of a MRTA problem, the system designer can  select suitable communication strategies that both minimizes the communication overhead and maximizes the performance of the group. And in other way, the communication capabilities of robots can guide a system designer to design interaction rules of robot teams, e.g. the specification of robot's on-board camera  can determine the degree of possible visual interactions among robots. The suitable trade-offs between these two axes: communication and interaction can give us a balanced design of our MRTA solution.
%The central issue of this paper is to study the performance of different communication and sensing strategies in an adaptive stochastic response-threshold task-allocation mechanism.  We have focused the benefits of traversing along the various axes of Fig. \ref{fig:mrta-complexities}. In this paper, we are interested on two distinct lines: 1) distributed task-allocation, with no direct robot-robot interaction and communication, say line $OX_{n}$ ($n$ being the number of robots)  and 2) distributed task-allocation, with no direct robot-robot interaction, but varying degrees of local communications, say line $X_{n}Z_{l}$  ($Z_{l}$ being a local broadcast communication strategy that involves $l$ number of peers in communication).
%===================================================================
\section{Multi-robot task-allocation using AFM}
\label{sec:afm-mrta}
\subsection{Attractive Field Model}
The probability of an agent choosing to perform a task is proportional to the strength of the task's attractive field, as given by Equation~\ref{eqn:afm3}.
\begin{equation}
P_{j}^{i} = \frac{S_{j}^{i}}{\sum_{j=0}^{J} S_{j}^{i}} \hspace*{0.25cm}where,\hspace*{0.25cm}S^{i}_{0} = S^{i}_{RW}   
\label{eqn:afm3}
\end{equation}
Equation~\ref{eqn:afm3} states that the probability of an agent, $i$, selecting a task, $j$, is proportional to the stimulus, $ S^i_j$, perceived from that task, with the sum of all the task stimuli normalised to $1$.

The strength of an attractive field varies according to how sensitive the agent is to that task, $k_{j}^{i}$, the distance between the task and the agent, $d_{ij}$, and the {\em urgency}, $\phi _{j}$ of the task.  In order to give a clear edge to each field, its value is modulated by the hyperbolic tangent function, $tanh$.  Equation~\ref{eqn:afm1} formalises this part of AFM.
%% S
\begin{equation}
S_{j}^{i} = tanh\{\frac{k_{j}^{i}}{d_{ij}+\delta } \phi _{j}\}
\label{eqn:afm1}
\end{equation}
Eqation~\ref{eqn:afm1}, used small constant $\delta$, called {\em delta distance}, to avoid division by zero, in the case when a robot has reached to a task.

Equation~\ref{eqn:afm2} shows how AFM handles the the no-task, or random walk, option.  The strength of the stimuli of the random walk task depends on the strengths of the fields real tasks.  In particular, when the other tasks have a low overall level of sensitisation, i.e., relatively weak fields, the strength of the random walk field if relatively high.  On the other hand, when the agent is highly sensitised, the strength of the random walk field becomes relatively low.  We use $J$ to denote the number of real tasks.  AFM effectively considers random walking as an ever present additional task.  Thus the total number of tasks becomes $J+1$. %--P(Task)
\begin{equation}
S^{i}_{RW} = tanh \left \{ 1 -  \frac{ \sum_{j=1}^{J} S^{i}_{j}}{J + 1} \right \}
\label{eqn:afm2}
\end{equation}
%-- P(RW)

A task $j$ has an associated urgency $\phi_j$ indicating its relative importance over time.  If an agent attends a task $j$ in time step $t$, the value of $\phi_j$ will decrease by an amount $\delta_{\phi_{DEC}}$ in the time-step $t+1$.  On the other hand, if a task has not been served by any of the agents in time-step $t$, $\phi_j$ will increase by a different amount, $\delta_{\phi_{INC}}$ in time-step $t+1$.  This behaviour is formalised in Equations~\ref{eqn:delta-phi1} and~\ref{eqn:delta-phi2}.
\begin{equation}
 If\hspace*{0.15cm}the\hspace*{0.15cm} task\hspace*{0.15cm}is\hspace*{0.15cm}not\hspace*{0.15cm}being\hspace*{0.15cm} done:\hspace*{0.15cm} \phi_{j,t+1} \rightarrow \phi_{j,t} \hspace*{0.15cm} + \delta_{\phi_{INC}}
\label{eqn:delta-phi1}
\end{equation}
%%
\begin{equation}
 If\hspace*{0.15cm}the \hspace*{0.15cm}task\hspace*{0.15cm}is\hspace*{0.15cm}being\hspace*{0.15cm}done:\hspace*{0.15cm}  \phi_{j,t+1} \rightarrow \phi_{j,t} \hspace*{0.15cm} - n\hspace*{0.10cm}\delta_{\phi_{DEC}}
\label{eqn:delta-phi2}
\end{equation}
Equation~\ref{eqn:delta-phi1} refers to a case where no agent attends to task $j$ and Equation~\ref{eqn:delta-phi2} to the case where $n$ agens are concurrently performing task $j$.

In order to complete a task, an agent needs to be within a fixed distance of that task.  When an agent performs a task, it learns about it and this will increases the probability of that agent selecting that task in the future.  This is done by increasing its sensitization to the task by a fixed amount, $k_{INC}$. The variable affinity of an agent, $i$, to a task, $j$, is called its {\em sensitization} to that task and is denoted $k^{i}_{j}$.  If an agent, $i$, does not do a task $j$, $k^i_j$ is decreased by a different fixed amount, $k_{DEC}$.  This behaviour is formalised in Equations~\ref{eqn:k-inc} and~\ref{eqn:k-dec}.
\begin{equation}
 If\hspace*{0.15cm}task\hspace*{0.15cm}is\hspace*{0.15cm}done:\hspace*{0.15cm}  k^i_j \rightarrow   k^i_j \hspace*{0.15cm} + \hspace*{0.15cm} k_{INC}
\label{eqn:k-inc}
\end{equation}
\begin{equation}
 If\hspace*{0.15cm}task\hspace*{0.15cm}is\hspace*{0.15cm}not\hspace*{0.15cm}done:\hspace*{0.15cm}  k^i_j \rightarrow   k^i_j \hspace*{0.15cm} - \hspace*{0.15cm} k_{DEC}
\label{eqn:k-dec}
\end{equation}

Each robot is modelled as an agent and each task is modelled as a spatial location.  The robots repeatedly select tasks and if the robot is outside a fixed task boundary, it navigates towards the task.  If the robot is within the task boundary it remains there until the end of the time step when a new (or the same) task is selected.
The distance between a task and a robot is simply the physical distance and the sensitivities are recorded as specific values on each robot.
The urgency values of the tasks are calculated based on the number of robots attending each task and the updated urgency values are communicated to the robots.

The sensing of the distance between the tasks and robots as well as the communication of urgency values are non-trivial in a robotic system.  Both the sensing and communication can be done either locally by the individual robots or centrally, through an overhead camera and a global communication network. This article presents work on exploring the effects of different sensing and communication models on the performance of MRTA systems.
%%-------------------

We have designed a set of  manufacturing shop-floor scenario experiments for validating the effectiveness of our AFM in producing self-regulated MRTA.  In this section, we have described our manufacturing shop-floor scenario and our task-allocation solution for robot-controllers.
%%%
%\begin{figure*}
%\centering
%\includegraphics[width=0.7\linewidth, angle=0]
%{./images/VSP.eps}
%%figure caption is below the figure
%\caption{A manufacturing shop-floor production and maintenance cycle}
%\label{fig:vsp}  % Give a unique label
%\end{figure*}
%--------------------------------------------
\subsection{A manufacturing shop-floor scenario}
\label{afm:vms}
By extending our interpretation of AFM in multi-robot system, we can set-up manufacturing shop-floor  scenario. Here, each task represents a manufacturing machine that is  capable of producing goods from raw materials, but they also require constant maintenance works for stable operations. Let $W_{j}$ be a finite number of material parts that can be loaded into a machine $j$ in the beginning of its production process and in each time-step, $\omega_{j}$ units of material parts can be processed  ($\omega_{j} \ll W_{j} $). So let $\Omega_{j}^{p}$ be the initial production workload of $j$ which is simply: $W_{j} / \omega_{j}$ unit.

We assume that all machines are identical. In each time step, each machine always requires a minimum threshold number of robots, called hereafter as {\em minimum robots per machine ($\mu$)}, to meet its constant maintenance work-load, $\Omega_{j}^{m}$ unit. However, if $\mu$ or more robots are present in a machine for production purpose, we assume that, no extra robot is required to do its maintenance work separately. These robots, along with their production jobs, can do necessary maintenance works concurrently. For the sake of simplicity, here we consider $\mu$ = 1.

Now let us fit the above production and maintenance work-loads and task performance of robots into a unit task-urgency scale. Let us divide our manufacturing operation into two subsequent stages: 1) \acfi{PMM}, and 2) \acfi{MOM}. Initially a machine starts working in PMM and does production and maintenance works concurrently. When there is no production work left, then it  enters into MOM. Fig. \ref{fig:vsp} illustrates this scenario for a single machine.

Under both modes, let $\alpha_{j}$ be the amount of workload occurs in a unit time-step if no robot serves a task and it corresponds to a fixed task-urgency $\Delta \phi_{INC}$. On the other hand, let us assume that in each time-step, a robot, $i$, can decrease a constant workload $\beta_{i}$ by doing some maintenance work along with doing any available production work. This  corresponds to a negative task urgency: $- \Delta \phi_{DEC}$. So, at the beginning of production process, task-urgency, occurred in a machine due to its production work-loads, can be encoded by Eq. \ref{eqn:task-urgency-prod-init}.
\begin{equation}
%\small
\Phi_{j, INIT}^{PMM} = \Omega_{j}^{p} \times \Delta \phi_{INC} + \phi_{j}^{m0}
\label{eqn:task-urgency-prod-init}
\end{equation}
where $\phi_{j}^{m0}$ represents the task-urgency due to any initial maintenance work-load of $j$.
Now if no robot attends to serve a machine, each time-step a constant maintenance workload of $\alpha_{j}^{m}$ will be added to $j$ and that will increase its task-urgency by $\Delta \phi_{INC}$. So, if $k$ time steps passes without any production work being done, task urgency at $k^{th}$ time-step will follow Eq. \ref{eqn:task-urgency-prod-case1}.
\begin{equation}
\Phi_{j, k}^{PMM} =\Phi_{j, INIT}^{PMM} + k \times \Delta \phi_{INC}
\label{eqn:task-urgency-prod-case1}
\end{equation}
However, if a robot attends to a machine and does some production works from it, there would be no extra maintenance work as we have assumed that $\mu$ = 1. Rather, the task-urgency on this machine will decrease by $\Delta \phi_{DEC}$ amount. If $\nu_{k}$ robots work on a machine simultaneously at time-step $k$, this decrease will be: $\nu_{k} \times \Delta \phi_{DEC}$. So in such cases, task-urgency in $(k+1)^{th}$ time-step can be represented by:
\begin{equation}
\Phi_{j, k+1}^{PMM} = \Phi_{j, k}^{PMM} - \nu_{k} \times \Delta \phi_{DEC}
\label{eqn:task-urgency-prod-case2}
\end{equation}
At a particular machine $j$, once $\Phi_{j, k}^{PMM}$ reaches to zero, we can say that there is no more production work left and this time-step $k$ can give us the {\em production completion time} of $j$, $T_{j}^{PMM}$. Average production time-steps of a shop-floor with M machines can be calculated by the following simple equation.
\begin{equation}
T_{avg}^{PMM} = \frac{1}{M} \sum_{j=1}^{M} T_{j}^{PMM} 
\label{eqn:avg-pmm}
\end{equation}
$T_{avg}^{PMM}$ can be compared with the minimum number of time-steps necessary to finish production works, $T_{min}^{PMM}$. This can only happen in an ideal case where all robots work for production without any random walking or failure. We can get $T_{min}^{PMM}$ from the total amount of work load and maximum possible inputs from all robots. If there are M machines and N robots, each machine has $\Phi_{INIT}^{PMM}$ task-urgency, and each time-step robots can decrease N $\times$ $\Delta \phi_{DEC}$ task-urgencies, then the theoretical $T_{min}^{PMM}$ can be found from the following Eq. \ref{eqn:min-pmm}.
%
%\begin{multicols}{2}
%\small
\begin{equation}
T_{min}^{PMM} = \frac{M \times \Phi_{INIT}^{PMM}}{N \times \Delta \phi_{DEC}} 
\label{eqn:min-pmm}
\end{equation}
%\vspace*{0.2cm}
\begin{equation}
\zeta_{avg}^{PMM} = \frac{T_{avg}^{PMM} - T_{min}^{PMM}}{T_{min}^{PMM}} 
\label{eqn:appd}
\end{equation}
%\end{multicols}
Thus we can define $\zeta_{avg}^{PMM}$, \acf{APCD} by following Eq. \ref{eqn:appd}:
%%
When a machine enters into MOM, only $\mu$ robots are required to do its maintenance works in each time step. So, in such cases, if no robot serves a machine, the growth of task-urgency will follow Eq. \ref{eqn:task-urgency-prod-case1}. However, if $\nu_{k}$ robots are serving this machine at a particular time-step $k^{th}$ , task-urgency at $(k+1)^{th}$ time-step can be represented by:
\begin{equation}
\Phi_{j, k+1}^{MOM} = \Phi_{j, k}^{MOM}- (\nu_{k} - \mu) \times \Delta \phi_{DEC}
\label{eqn:task-urgency-maint-case}
\end{equation}
By considering $\mu = 1$, Eq. \ref{eqn:task-urgency-maint-case} will reduces to Eq. \ref{eqn:task-urgency-prod-case2}. Here, $\Phi_{j, k+1}^{MOM}$ will correspond to the {\em pending maintenance work-load} of a particular machine at a given time. This happens due to the random task switching of robots with a no-task option (random-walking). Interestingly PMW will indicate the robustness of this system since higher PMW value will indicate the delay in attending maintenance works by robots. We can find the \acfi{APMW} per time-step per machine, $\chi_{j}^{MOM}$ (Eq. \ref{eqn:sigle-pmw}) and average PMW per machine per time-step, $\chi_{avg}^{MOM}$ (Eq. \ref{eqn:avg-pmw}).
%\begin{multicols}{2}
%\small
\begin{equation}
\chi_{j}^{MOM}= \frac{1}{K} \sum_{k=1}^{K} \Phi_{j, k}^{MOM}
\label{eqn:sigle-pmw}
\end{equation}
%\vspace*{0.2cm}
\begin{equation}
\chi_{avg}^{MOM}= \frac{1}{M} \sum_{j=1}^{M} {\chi_{j}^{MOM}}
\label{eqn:avg-pmw}
\end{equation}
%\end{multicols}
%----------------------------------------------------------------
\subsection{Robot-controller algorithms}
\label{ss:rcc-alg}
In our task-allocation algorithm, for each task, we extract its pose, urgency, sensitisation from input data. \textit{CalculateTaskDistance()} function calculates the Euclidian distance between a task and a the robot by taking the current robot-pose and static task-pose as the input. These values are enough to get a task's stimuli based on Eq. \ref{eqn:afm1}. We get the random-walk task's stimuli from Eq. \ref{eqn:afm2}.\\

\textbf{Algorithm 1: Self-regulated task-allocation by AFM}
\vspace{-3mm}
\newline
\HRule
\begin{algorithmic}[1]
\begin{small}
\label{alg:task-selector}
\State $\textbf{Input: } AllTaskInfo, RobotPose, TaskRecords, DeltaDistance$
\State $\textbf{Output: } SelectedTaskID$
\State \COMMENT {Stage 1: Get  sum  of stimulus of all tasks}
\State $TotalTasks \gets$  Total number of tasks $\in AllTaskInfo$  
\State $ TaskStimuliSum \gets 0 $
\ForAll {$ Task \in AllTaskInfo $} 
\State $ TaskPose \gets  $ Task-position  $ \in Task$
\State $ TaskUrgency \gets $ Task-urgency $ \in Task$
\State $ TaskSensitization \gets $ Task-sensitization $\in Task$
\State $ DistToTask \gets$
\textbf{CalculateTaskDistance(}
\newline
$RobotPose$, $TaskPose$\textbf{)}
\State $ TaskStimuli \gets  $ \textbf{CalculateTaskStimuli(}
\newline
$DistToTask, TaskSensitization, TaskUrgency, DeltaDistance$\textbf{)}
\State $ TaskStimuliSum \gets$  $TaskStimuliSum + TaskStimuli$
\State $ TaskRecords \gets $ \textbf{UpdateTaskRecords(\\}$TaskStimuli,DistToTask, TaskUrgency,$\\ $TaskSensitization\textbf{)}$
\EndFor
%%
\State $RandomWalkStimuli \gets $ \textbf{CalculateRandomWalkStimuli(\\}$TotalTasks,$ %\hspace*{4.5cm}
 $TaskStimuliSum$\textbf{)}
\State $ AllStimuliSum \gets TaskStimuliSum + RandomWalkStimuli $
%%
\State \COMMENT {Stage 2: Find probability of doing each task }
\State $ TaskID \gets 0 $ 
\While {$ TaskID \leq TotalTasks $} 
\State $ TaskStimuli \gets $ Task-stimuli $\in TaskRecords(TaskID)$
\State $ TaskProbability \gets  $ \textbf{GetTaskProbability(\\}$TaskStimuli, AllStimuliSum$\textbf{)}
\State $ TaskProbabilityRange \gets $
\newline
 \textbf{ConvertTaskProbabilityIntoRange(}\\ $TaskProbability$\textbf{)}
\State $ TaskRecords \gets  $ \textbf{UpdateTaskRecords(}$TaskProbability$\textbf{)}
\EndWhile
%%
\State \COMMENT {Stage 3: Draw a random-number to match TaskID}
\State $ RandomNum \gets  $ 
\newline
\textbf{GetRandomNumber(}$0,$ \textbf{Max(}$TaskProbabilityRange$\textbf{))}
\While {$ TaskID \leq TotalTasks $} 
\State $ RangeStart \gets  $ \textbf{Min(}$TaskProbabilityRange (TaskID)$\textbf{)}
\State $ RangeEnd \gets  $ \textbf{Max(}$TaskProbabilityRange (TaskID)$\textbf{)}
\If {$  RandomNum \geq RangeStart$ \newline $\hspace*{.25cm}\&\& \hspace*{.25cm} RandomNum  \leq  RangeEnd $}
\State $ SelectedTaskID \gets TaskID $ 
\EndIf
\EndWhile
\end{small}
\end{algorithmic}
\vspace{-3mm} 
\HRule\\
%%
In the second stage of our task-allocation algorithm, we  find the probability of each task (including random-walk) based on Eq. \ref{eqn:afm3}. Then this probability value of each task, between 0 and 1, is rounded to the closest two-digit fractions and multiplied by 100 and put into a linear scale. Then we use a random-number generator that draws a random-number between 0 and the highest value of task-probability range. Then this random number is compared against the task probability range of each task. Under this probabilistic method, the task with larger probability range has a  higher chance to be selected, but low probability tasks can also be selected time-to-time.\\

\textbf{Algorithm 2: Robot's learning and forgetting of tasks}
\vspace{-3mm}
\newline
\HRule
\begin{algorithmic}[1]
\begin{small}
\label{alg:update-sz}
\State $\textbf{Input: }  TaskRecords, LeranRate, ForgetRate, SelectedTaskID$
\State $\textbf{Output: }$ Updated $TaskSensitisation \in TaskRecords$
\ForAll {$ Task \in TaskRecords $} 
\State $ TaskID \gets  $ ID $\in Task$
\State $ TaskSensitization \gets  $   Sensitisation $ \in Task$
\If {$  TaskID \equiv SelectedTaskID $}
\State $ TaskSensitization \gets $ \textbf{Max(}$1, (TaskSensitization + LeanRate)$\textbf{)}
\Else
\State $ TaskSensitization \gets $ \textbf{Min(}$0, (TaskSensitization - ForgetRate)$\textbf{)}
\EndIf
\EndFor
\end{small}
\end{algorithmic}
\vspace{-3mm} 
\HRule\\

Algorithm 2 lists the pseudo-code for updating (learning and forgetting) the robot's task-sensitization values. Along with previously mentioned \textit{TaskRecords}, and  \textit{SelectedTaskID}, it takes two other inputs: \textit{LeranRate} ($\Delta k_{INC} $) and \textit{ForgetRate} ($\Delta k_{INC} $) as outlined in Eq. \ref{eqn:k-inc} and \ref{eqn:k-dec} respectively.  In addition to that it also keep the value of task-sensitization between the fixed limit of 0 and 1.
%====================================================================
\section{Communication models}
\label{sec:comm-model}
\subsection{Centralized communication model}
\begin{figure}
\centering
\includegraphics[width=.7\columnwidth, angle=0]{./images/CentralizedComm.eps}
\caption{\small A centralized communication scheme} % for implementing AFM}
\label{fig:ccm} % Give a unique label
\end{figure}
%%
AFM relies upon a system-wide continuous flow of information which can be realized using any suitable communication model. A simple centralized communication scheme is outlined in Fig. \ref{fig:ccm}. In this model we have used bi-directional signal-based exchange of communication messages between a centralized \textit{task perception server} (TPS) and a \textit{robot-controller client} (RCC). The main role of TPS is to send up-to-date task-information to RCCs. This  task-information mainly contains the location and urgency of all tasks  which is used by the RCCs for running their task-allocation algorithm. The urgency value of each task is dynamically updated  by TPS after receiving the  status signals from the working robots of that particular task. Fig. \ref{fig:ccm} shows how three robots are attracted to two different tasks and their communications with TPS. Here although the robots are selecting task independently based-on the strength of their attractive fields to different tasks, they are depended on the TPS for task-information.
%%
%\subsection{General characteristics}
%
%We can characterize our communication model in terms of three fundamental issues of communication \cite{Gerkey+2001}. 
%\begin{enumerate}
%\item Message content: {\em what to communicate?}
%\item Communication frequency: {\em when to communicate?}
%\item Target message recipients: {\em with whom to communicate?}
%\end{enumerate}
%%%
AFM suggests the communication of task-urgencies  among robots. This communication helps the robots to gain information that can be  treated as ``global sensing''. However in this model  robots do not communicate among themselves. Hence this model can be approximated as the GSNC strategy. Since in order to run the task-allocation algorithm robot-controllers need the distance information we also include the task position information in  the message. Our centralized communication model is open to include any further information, such as time-stamp, in the message payload. In this centralized communication model the frequency of signal emission depends on several issues, e.g. the rate at which the environment is changing, the bandwidth of communication medium. In case of time-extended tasks, robots can receive information less frequently and the  bandwidth usage can be kept  minimum. However under a fast changing environment relatively more bandwidth will be required.  Finally the centralized communication model spread the attractive fields of all tasks globally by broadcasting information to all robots.  
%%
%\subsection{Algorithm}

The algorithm that updates the task-urgencies in TPS is given here.\\
\textbf{Algorithm 3: Task-urgency update rules based on AFM}
\vspace{-3mm}
\newline
\HRule
%% ALG
\begin{algorithmic}[1]
\begin{small}
\label{alg:tps}
\State $\textbf{Input: } AllTaskInfo, AllTaskWorkers, ThresholdWorkers,$\\ \hspace*{1cm}$DeltaUrgencyINC, DeltaUrgencyDEC$
\State $\textbf{Output: }$ Updated $TaskUrgencies \in AllTaskInfo$
\ForAll {$ (Task, Workers) \in (AllTaskInfo, AllTaskWorkers) $} 
\State $ TaskUrgency \gets $ Task-urgency $\in Task$
\State $ TaskWorkers \gets $ Number of workers $ \in Workers$
\If {$ TaskWorkers < ThresholdWorkers $}
\State $ TaskUrgency \gets $ \textbf{Max(}$1, (TaskUgerncy + DeltaUrgencyINC)$\textbf{)}
\Else
\State $ TaskUrgency \gets $ \textbf{Min(}$0, (TaskUgerncy - $\\ \hspace*{5.3cm}$ TaskWorkers \times DeltaUrgencyDEC)$\textbf{)}
\EndIf
\EndFor
\end{small}
\end{algorithmic}
%%
\vspace{-3mm} 
\HRule\\
%%
The above algorithm relies on the previously mentioned task-status signals from the working robots.  It sorts out the worker robots' robot-id according to their task-id and use the worker count to determine whether the corresponding task-urgency needs any change  according the rules of AFM. For example, here we have shown that if the number of working robots exceeds a pre-set threshold task urgency has been updated based on Eq. \ref{eqn:delta-phi1} and \ref{eqn:delta-phi2}. Moreover, in order to satisfy our interpretation of AFM, the task-urgency values are kept within a fixed range 0 and 1.
%%
%\subsubsection{Implementation strategy}
%Our centralized communication model has been implemented by the D-Bus interprocess communication technology \cite{Pennington+2010}. Under this implementation, we have used D-Bus \textit{signal} type asynchronous messages to enable information sharing among SwisTrack multi-robot tracker \cite{Lochmatter+2008}, TPS and RCCs inside a single host. D-Bus signals give us the flexible, fault-tolerant and real-time messaging scheme which can not be easily achieved in other interprocess communication schemes. The detail design of our  D-Bus implementation can be found in \cite{Sarker2010control}. The specific implementation of signals and their payloads are discussed in Sec. \ref{afm:impl}.
%==============================================================
\subsection{Local P2P communication model (LPCM)}
In most swarm robotic research local communication is considered as the one of the most critical components of the swarms where the global behaviours emerges from the local interactions among the individuals and their environment. In this study, we have used the concepts of pheromone active-space of ants to realize our simple LSLC scheme. Ants use various chemical pheromones with different active spaces (or communication ranges) to communicate different messages with their group members \cite{Holldobler1990}. Ants sitting near the source of this pheromone sense and respond quicker than others who wander in far distances. Thus both communication and sensing occurs within a small communication range\footnote{Although, generally communication and sensing are two different issues, however within the context of our self-regulated MRTA, we have broadly viewed sensing as the part of communication process, either implicitly via environment, or explicitly via local peers.}. We have used this concept of communication range or locality in our LPCM. A suitable  range (or radius) of communication and sensing can be set at design time based on the capabilities of robots \cite{Agassounon+2002}. Alternately they can also be varied dynamically over time depending on the  cost of communication and sensing, e.g. density of peers, ambient noise in the communication channels, or even by aiming for maximizing information spread  \cite{Yoshida+2000}. In this study, we have followed the former approach as our robots do not have the precise hardware to dynamically vary their communication and sensing ranges. Below we describe the general characteristics and implementation algorithm and strategy of LPCM.
%%---------------------------------------------------------
%\subsection{General characteristics}
Our LPCM relies on the local P2P communications among robots. we have assumed that robots can communicate to its nearby peers within a certain communication radius, $r_{comm}$ and they can sense tasks within another radius $r_{task}$. They exchange communication signals reliably without any significant loss of information. A robot $R_1$ is a {\em peer} of robot $R_2$, if spatial distance between $R_1$ and $R_2$ is less than this $r_{comm}$.
Similarly, when a robot comes within this $r_{task}$ of a task, it can sense the status of this task. Although the communication and sensing  range can be different based on robot capabilities, we have considered them same for the sake of simplicity of our implementation.

Local communication can also give robots similar task information as in centralized communication. In this case, it is not necessary for each robot to communicate with every other robot to get information on all tasks. Since robots can random walk and explore the environment we assume that for a reasonably high robot-to-space density, all tasks will be known to all robots after an initial exploration period. In order to update the urgency of a task, robots can estimate the number of robots working on a task in two ways:  by either using their sensory perception (e.g. on-board camera) or  doing local P2P communication with others.

Similar to our centralized communication model, we can characterize our local communication model in terms of message content, communication frequency and target recipients \cite{Gerkey+2001}. Regarding the issue of message content, our local communication model is open. Robots can communicate with their peers with any kind of message. Our local model addresses the last two issues very specifically. Robots communicate only when they meet their peers within a certain communication radius ($r_{comm}$). Although in case of an environment where robots move relatively faster the peer relationships can also be changed dynamically. But this can be manipulated by setting the signal frequency and robot to space density to somewhat reasonably higher value.

In terms of target recipients, our model differs from a traditional publish/subscribe communication model by introducing the concept of dynamic subscription. In a traditional publish/subscribe communication model, subscription of messages happens prior to the actual message transmission. In that case prior knowledge about the subjects of a system is necessary. But in our model this is not necessary as long as all robots uses a common addressing convention for naming their incoming signal channels. In this way, when a robot meets with another robot it can infer the address of this peer robot's channel name by using a shared rule. A robot is thus always listening to its own channel for receiving messages from its potential peers or message publishers. On the other side, upon recognizing a peer, a robot sends a message to this particular peer. So here neither it is necessary to create any custom subject name-space  \cite{Gerkey+2001} nor we need to hard-code information in each robot controller about the knowledge of their potential peers {\em a priori}. %Subscription is done automatically based on their respective $r_{comm}$.
%
%%----------------------------------------------------------------
%\subsection{Algorithm}
%%
\textbf{\small Algorithm 4: Locality based P2P Communication Model}
\vspace{-3mm}
\newline
\HRule
\begin{algorithmic}[1]
\label{alg:lpcm}
\State $\textbf{Input: } RobotID, r_{comm}, r_{task}, TaskInfoDB, RobotPose,$\\ \hspace*{1cm}$ListeningBuffer, EmissionBuffer$
\State $\textbf{Output: }$ updated $TaskInfoDB$
\State \COMMENT {Perception of a task, if the robot is within $r_{task}$}
\State $ TaskPose \gets $ Estimate/get pose of a task within $r_{task}$
\State $ TaskUrgency \gets $ Estimate/get urgency of a task within $r_{task}$
\State $ TaskInfo \gets (TaskPose, TaskUrgency) $ 
\State $TaskInfoDB \gets$
\newline
\textbf{UpdateTaskInfoDB(}$TaskInfo$\textbf{)}
% P2P Interaction, listen signal
\State \COMMENT {Listening \textit{\textit{LocalTaskInfo}} signal(s) from peers}
\State $ RobotPeers \gets $ Identify/get a list of peers within $r_{comm}$
\ForAll {peer $\in RobotPeers$}
\If {(caught a \textit{\textit{LocalTaskInfo}} signal from nearby peer)}
\State $ListeningBuffer \gets $ \textit{\textit{LocalTaskInfo}} of peer
\State $TaskInfoDB \gets$
\newline 
\textbf{UpdateTaskInfoDB(}$ListeningBuffer$\textbf{)}
\EndIf
\EndFor
%%
\State \COMMENT {Emitting own \textit{\textit{LocalTaskInfo}} signal to peers}
\State $ EmissionBuffer \gets TaskInfoDB$
\ForAll {peer $\in RobotPeers$}
\State \textbf{EmitLocalTaskInfoSignal(}peer, $EmissionBuffer$ \textbf{) }
\EndFor
\State $RobotPeers \gets 0$
\end{algorithmic}
\vspace{-3mm} 
\HRule\\
Within the context of our self-regulated MRTA experiments under AFM,  we have formalized the following three aspects of LPCM into an implementation algorithm. 
\begin{enumerate}
\item Sensing the presence of the local peers and task, if any.
\item Listening to the task-information signals from local peers.
\item Emitting local task-information signals to local peers.
\end{enumerate}
%%
From Algorithm 4, we see that a robot controller is initialized with its specific $RobotID$ and default values of $r_{comm}$ and $r_{task}$ that correspond to the robot's communication and sensing ranges respectively. We have assumed that these values are same for all robots and for all tasks. Initially a robot has no information about tasks, i.e. {$TaskInfoDB$}, $ListeningBuffer$ and $EmissionBuffer$ all are empty. Upon sensing a task, robot determines the task's pose and urgency of that task. This is not strictly necessary as this information can also be available from alternate sources, e.g. via communicating with a TPS which is discussed later.

Robot controller then executes the \textbf{UpdateTaskInfoDB()} that modified the robot's information about the corresponding task. In second step, robot senses its nearby peers located within $r_{comm}$. The potential \textit{LocalTaskInfo} signal reception from a  peer again triggers the \textbf{UpdateTaskInfoDB()} function. In the last step, robot emits its own task information as a \textit{LocalTaskInfo} signal to its peers.

%\subsection{Implementation strategy}
%In order to implement LPCM, our centralized communication scheme has been converted into a decentralized one where robots can use local observation and communicate with peers about tasks to estimate task-urgencies. Under this implementation, we present an emulation of this scenario where robots do not depend entirely on TPS for estimating task-urgencies, instead they get task information from TPS when they are very close to a task (inside $r_{task}$) or from local peers who know about a task via TPS. The specific implementation of P2P signals are discussed in Sec. \ref{afm:impl}.
%=====================================================================
\section{Experimental design}
\label{sec:expt-design}
The overall aim of our MRTA experiments is to compare the various properties of self-regulated MRTA under both GSNC and LSLC strategies. These experiments are grouped into four series labelled using the following letters: \textit{A, B, C} and \textit{D}. Series A and B experiments are done using a centralized communication system under GSNC strategy and Series C and D experiments are carried out using an emulated local P2P communication under LSLC stategty. Below we describe the observables, parameters and implementation of our experiments.
%----------------------------------------------------------
\subsection{Observables}
%\textbf{Plasticity:} %As we have discussed in Sec. \ref{bg:def:dol},  
%Self-regulated MRTA is often characterised by the plasticity and task-specialization, in both macroscopic and microscopic levels. Within our manufacturing shop-floor context, plasticity refers to the collective ability of the robots to switch from doing no-task option (random-walking) to doing a task (or vice-versa) depending on the work-load present in the system. Here we expect to see that most of the robots would be able to engage in tasks when there would be high workloads (or task-urgencies) during PMM. Similarity, when there would be low workload in case of MOM, only a few robots would do the task, rest of them would either be idle (not doing any task) or perform a random-walk.  The changes of task-urgencies and the ratio of robots engaged in tasks can be good metrics to observe plasticity in MRTA.
%
%\textbf{Task-specialization:} Self-regulated MRTA is generally accompanied with task-specializations of agents. That means that few robots will be more active than others. From the interpretation of AFM, we can see that after doing a task a few times, a robot will soon be sensitized to it. Therefore, from the raw log of task-sensitization of robots, we can be able to find the pattern of task-sensitization of robots per task basis.
%
%\textbf{Quality of task-performance:} As discussed in Sec. \ref{afm:vms} we can measure the quality of MRTA from the APCD. It first calculates the ideal minimum production time and then finds the delay in production process from the actual production completion data. Thus this will indicate how much more time is  spent in the production process due to the self-regulation of robots in this distributed task-allocation scheme.  In order to calculate APCD, we can find the production completion time for each task from the raw log of task-urgency and make an average from them.
%
%\textbf{Robustness:} In order to see if our system can respond to the gradually increasing workloads,  we can measure APMW within the context of our manufacturing shop-floor scenario. This can show the robustness of our system. When a task is not being served by any robot for some time we can see that its urgency will rise and robots will respond to this dynamic demand. For measuring APMW we need only the task-urgency data.
%
%\textbf{Flexibility:} From the design of AFM, we know that robots that are not doing a task will be de-sensitized to it or forget that task. So at an overall low work-load (or task urgency), less robots will do the tasks and hence less robots will have the opportunity to learn tasks. From the shop-floor work-load data, we can confirm the presence of flexibility in MRTA.
%
%\textbf{Energy-efficiency:} In order to characterize the energy-efficiency in MRTA we can log the pose data of each robot that can give us the total translations occurred by all robots in our experiments. This can give us a rough indication of energy-usage by our robots. 
%
%\textbf{Information flow:} Since AFM requires a system-wide continuous flow of information, we can measure the communication load to bench-mark our implementation of communication system. This bench-mark data can be used to compare among various communication strategies. Here we can measure  how much task-related information, i.e. task-urgency, location etc. are sent to the robots at each time step. This  amount of information or communication load can be constant or variable depending on the design of the communication system.
%
%\textbf{Scalability:} In order to see the effects of scaling on MRTA, we have designed two group of experiments. Series A corresponds to a small group where we have used 8 robots, 2 tasks under an arena of 2 $m^2$. We have doubled these numbers in Series B, C and D, i.e. 16 robots, 4 tasks under an arena of 4 $m^2$. This proportional design can give us a valuable insight about the effects of scaling on self-regulated MRTA. 

Thus, in order to observe the above properties of self-regulated MRTA , we have designed our experiments to record the following  observables in each time-step.
\begin{enumerate}
\item Task-urgency of each task ($\phi$).
\item Number of robots engaged in each task.
\item Task-sensitizations ($k$) of robots.
\item Pose data of robots.
\item Communication of task-information message among TPS and RCCs.  
\end{enumerate}
%%
\begin{table}
\caption{Experimental parameters of Series A \& B experiments}
\label{table:params}
\begin{center}
\begin{tabular}{|p{1.5in}|c|}
\hline Parameter & Series A $\mid$ Series B\\
\hline Total number of robots ($N$) & \hspace*{0.1cm} 8 $\mid$ 16\\
\hline Total number of tasks ($M$) & 2 $\mid$ 4\\
\hline Experiment area ($A$) & 2 $m^2$ $\mid$  4 $m^2$\\
\hline Initial production work load/machine ($\Omega_{j}^{p}$) & 100 unit \\
\hline Task urgency increase rate ($\Delta\phi_{INC}$) & 0.005\\
\hline Task urgency decrease rate ($\Delta\phi_{DEC}$) & 0.0025\\
\hline Initial sensitization ($K_{INIT}$) & 0.1\\
\hline Sensitization increase rate ($\Delta k_{INC}$) & 0.03\\
\hline Sensitization decrease rate ($\Delta k_{DEC}$) & 0.01\\
\hline
\end{tabular}
\end{center}
\end{table}
%%
%------------------------------------------------------------
\subsection{Parameters}
Table \ref{table:params} lists a set of essential parameters of our GSNC startegy based experiments (Series A and B). We intend to have a set-up that is relatively complex, i.e., with a high number of robots and tasks in a large area. The diameter of the marker of our e-puck robot is 0.08m. So, if we put 4 robots in an area of one square meter, this will give us a robot-occupied-space to free-space ratio of about 1:49 per square meter. This ratio is reasonable in order to allow the robots to move at a speed of 5 cm/sec without causing much interference to each other. 

The initial values of task urgencies correspond to 100 units of production work-load without any maintenance work-load as outlined in Eq. \ref{eqn:task-urgency-prod-init}. We choose a limit of 0 and 1, where 0 means no urgency and 1 means maximum urgency. Same rule applies to sensitisation, where 0 means no sensitisation and 1 means maximum sensitisation. This also implies that if sensitization is 0, task has been forgotten completely. On the other hand, if sensitization is 1, the task has been learnt completely. We choose a initial sensitization value of 0.1 for all tasks. The following relationships are maintained for selecting task-urgency and sensitization parameters.
\begin{equation}
\Delta\phi_{INC} = \frac{\Delta\phi_{DEC} \times N}{2 \times M}
\label{eqn:task-urgency}
\end{equation}
%
\begin{equation}
\Delta k_{DEC} = \frac{\Delta k_{INC}} {M - 1} 
\label{eqn:sensitization}
\end{equation}
%
Eq. \ref{eqn:task-urgency} establishes the fact that task urgency will increase at a higher rate than that of its decrease. As we do not like to keep a task left unattended for a long time we choose a higher rate of increase of task urgency. This difference is set on the basis of our assumption that at least half of the expected number of robots (ratio of number of robots to tasks) would be available to work on a task. So they would produce similar types of increase and decrease behaviours in task urgencies.

Eq. \ref{eqn:sensitization} suggests that the learning will happen much faster than the forgetting. The difference in these two rates is based on the fact that faster leaning gives a robot more chances to select a task in next time-step and thus it becomes more specialized on it.

%% local
Our LSLC startegy based experiments (Series C and D) follow the similar design of experimental parameters and observables of Series B experiments as outlined above. Table \ref{table:local-expt-design} highlights the major parameters of these experiments. For the sake of simplicity, the communication and sensing range values are kept same in both series of experiments.
Series D uses larger ranges that enables our robot to capture more task information at a time. That is similar to  ``global sensing and global communication'' of information by the robots, since in a large group of robots, it is not often practical that a robot communicates with all other robots. On the other hand, Series C uses the half of the range values of Series D. This enables our robots to capture less information, that mimics a close LSLC strategy. 
%%
\begin{table}
\caption{Experimental parameters of Series C \& D experiments}
\label{table:local-expt-design}
\begin{center}
\begin{tabular}{|l|c|c|}
\hline Parameter & \hspace*{0.2cm} Series C $\mid$ Series D\\
\hline task-perception range ($r_{task}$) & $0.5 m \mid 1 m$\\
\hline Communication range ($r_{comm}$) & $0.5 m \mid 1 m$\\
\hline Total number of robots ($N$) & 16 \\
\hline Total number of tasks ($M$) & 4 \\
\hline Experiment area ($A$) & 4 $m^2$\\
\hline
\end{tabular}
\end{center}
\end{table}

%==============================================================
\section{Implementation}
\label{sec:imp}
%%
\begin{figure*}
\centering
\includegraphics[width=0.9\textwidth, angle=0]
{./images/RIL-Expt-Setup1.eps}
%figure caption is below the figure
\caption{Hardware and software setup for series A \& B experiments}
\label{fig:RIL-Expt-Setup1} % Give a unique label
\end{figure*}
%%
Ideally, AFM can be implementation as a complete distributed task-allocation system where each agent selects its own task based on its own external perception about task-urgencies (i.e. attractive fields),  distances from tasks and internal task-sensitisation records. Such an implementation requires powerful robots with sophisticated sensors (camera, laser etc.) and sufficient computation and communication  capabilities. In that case, robots can keep  task-urgency information up-to-date  through suitable local communication  schemes with their peers who can monitor the tasks. By using suitable navigation and mapping modules, they can also accurately calculate the distances from tasks and navigate to tasks autonomously. Moreover, they also require necessary hardware to do the actual task, e.g. gripper for picking up objects. However, in this study, we are particularly interested to find the suitable communication schemes that can effectively spread the attractive fields (task-urgencies) among robots. So we have simplified the complexities of a full-fledged implementation by using a centralized communication system  that effectively makes up the limitations of our e-puck robots.  For example, our robots are not  capable of sensing a task to estimate its urgencies, instead our centralized TPS broadcast task information, e.g. task-urgencies, locations etc. to robots in certain time intervals. 

\begin{figure*}
\centering
\hspace*{1cm}
%\includegraphics[width=10cm,height=7.5cm,angle=0]
\subfloat[]{
\includegraphics[width=0.65\linewidth,angle=0]
{./images/RILSnapshot1.eps}}
\newline
\subfloat[]{
\includegraphics[width=0.65\linewidth]
{./images/RILCamcorderSnapshot1.eps}}
\caption{Our experiment arena captured by (a) a GigE4900C camera mounted on 3m high ceiling (b) an ordinary camcorder.}
\label{fig:expt-arena} % Give a unique label
\end{figure*}
%%
In our current implementation, instead of doing any real work with powerful robots, we emulate a mock manufacturing shop-floor scenario that requires the robot only to travel among tasks. As our robots do not have on-board CPU, they need a host PC to  control them using BTCom Bluetooth communication protocol over the wireless link \cite{Mondada+2009}. Thus our host-PC runs one RCC for each physical robot. These RCCs also rely upon SwisTrack multi-robot tracking system for updating their real-time pose. So although our MRTA solution is distributed by design, we primarily used a centralized approach to implement it due to the limitations of our robots and the convenience of implementation. Table \ref{table:dbus-signals} list the D-Bus communication interfaces among our software components. Fig. \ref{fig:concrete-arch} outlines the placements of various software components of our multi-robot control architecture based on their functional characteristics and processing requirements \cite{Sarker2010control}.
%%
\begin{table*}
\caption{D-Bus signal interfaces among software components.}
\label{table:dbus-signals}
\begin{center}
\begin{tabular}{|l|l|l|p{1.8in}|p{0.5in}|}
\hline D-Bus Signal &  Source & Destination  & Payload & Used in\\ 
\hline RobotPose & SwisTrack & RCC  & Robot-pose x, y and oientation theta. & GSNC \& LSLC\\ 
\hline TaskInfo & TPS & RCC & An array of all tasks' information each of them contains: task-id, time-stamp, task pose (x,y), task-urgency. & ,, \\ 
\hline RobotStatus & RCC & TPS & Robot's id and its currently executing task's id. & ,, \\ 
\hline RobotPeers & SwisTrack & RCC & List of IDs of peers of each robot within its communication range. & LSLC \\ 
\hline TaskNeighbour & SwisTrack & TPS &  List of IDs of robots that are co-located within a task's perception range. & ,,\\ 
\hline LocalTaskInfo & RCC & RCC & An array of known tasks' information. & ,,\\
\hline 
\end{tabular}
\end{center} 
\end{table*}
%%
\begin{figure*}
\begin{center}
\includegraphics[width=0.7\linewidth,height=10cm]{./images/concrete-arch} 
%\centering
\caption{General outline of {\em HEAD}. A RCC application has been split into two parts: one runs locally in server PC and another runs remotely, e.g., in an embedded PC.} 
\label{fig:concrete-arch}
\end{center}
\end{figure*}
%%
\begin{figure*}
\centering
\includegraphics[width=0.7\linewidth,height=10cm]
{./images/SwisTrackScreenshot.eps}
\caption{SwisTrack tracking a team of 16 robots under Ubuntu Linux 9.10 OS.}
\label{fig:swistrack-screenshot} 
\end{figure*}
%-----------------------
\subsubsection{RCC Modules}
As shown in Fig. \ref{fig:RIL-Expt-Setup1}, each e-puck robot is controlled by a corresponding RCC. A RCC sends commands to the robot's firmware using BTCom protocol. A RCC consists of several Python modules. Each module represents a sub-process under a main process that ties all of them together by using Python's Multiprocessing module\footnote{http://docs.python.org/library/multiprocessing.html}. Below we have described briefly the implementation of these Python modules. All code are publicly accessible through GitHub repository\footnote{git://@github.com/roboshepherd/EpuckCentralizedClient.git,    
\textit{hash:}7e3af8902e64db3fa59e}.
%%
%%
\begin{table}
\caption{Data structures and events used by the RCC}
\begin{center}
\begin{tabular}{|l|l|}
\hline \textbf{Data structure} & \textbf{Related event(s)}\\ 
\hline \texttt{\texttt{mRobotID}} & - \\ 
\hline \texttt{mRobotPose} & \texttt{mRobotPoseAvailable}\\ 
\hline \texttt{mTaskInfo} & \texttt{mTaskInfoAvailable}\\ 
\hline \texttt{mSelectedTask} & \texttt{mSelectedTaskAvailable}\\
 &  \texttt{mSelectedTaskStarted}\\
 &  \texttt{mTaskTimedOut}\\
 \hline 
\end{tabular}
\end{center}
\label{table:data-mgr}
\end{table} 
%---------------------
In the implementation of RCC, we have employed a data and event management process called \texttt{DataManager} that acts as a data warehouse and event management centre for RCC. Table \ref{table:data-mgr} list the major data structures and corresponding event channels of \texttt{Data Manager}. Here \texttt{mRobotID} represents the e-puck robot's marker ID (converted to decimal number from the binary code) which uniquely identifies a robot from others.  We have used Python {\em dictionary} type data structure for all other data structures that are managed by the Python Multiprocessing's {\em Manager()} object.  \texttt{DataManager} object also runs a tiny TCP/IP server process powered by the Multiprocessing's {\em RemoteManager()} interface. So, if necessary,  any other process can access all of the DataManger's data structures and event channels remotely by instantiating a proxy client  that connects to this TCP/IP server process.

We have employed two D-Bus communication modules in RCC: \texttt{SignalListener} and \texttt{SignalEmitter}, that are responsible for listening and emitting D-Bus signals respectively. \texttt{SignalListener}, has subscribed to D-Bus session bus for listening  to D-Bus \texttt{RobotPose} and \texttt{TaskInfo} signals. \texttt{SignalEmitter} makes use of Python {\em sched} module that enables it to check periodically \texttt{mSelectedTaskStarted} event and emit a robot's task status containing signal, \texttt{RobotStatus}. \texttt{TaskSelector} works in the application layer of our multi-robot control architecture. It plugs the AFM algorithms (Sec. \ref{ss:rcc-alg}) into RCC to select task based-on \texttt{DataManger}'s event notifications.
%%
\begin{figure*}
\centering
\includegraphics[width=0.7\linewidth,height=11cm]
{./images/rcc-device-controller-state.eps}
%figure caption is below the figure
\caption{State diagram of \texttt{DeviceController} module}
\label{fig:dc-states} % Give a unique label
\end{figure*}

%The final code that moves a robot to desired task location or make random-walk resides in \texttt{DeviceController} module. When \texttt{TaskSelector} sets  \texttt{mSelectedTaskAvailable} event \texttt{DeviceController} sub-process checks the Bluetooth link-connectivity with physical robot. In case of successful task start-up it sets \texttt{mSelectedTaskStarted} event that, in turn, triggers \texttt{SignalEmitter} to emit a D-Bus signal publishing the robot's currently engaged task. The full state switching policies of \texttt{DeviceController} is illustrated in Fig. \ref{fig:dc-states}. Externally we can observe two distinct physical state of a robot: it is either idle or in motion (separated by dotted line). These two physical states are mapped into several logical steps as described below.
%
%\textbf{DeviceUnavailable: }
%Periodically \texttt{DeviceController} checks whether the device has connected to host-PC and changes its state to \textit{DeviceAvailable} (i.e device connected). We can see that from every other state, device can come to this unavailable state (shown by dotted arrow) when the  link is lost e.g. in case of robot's low battery or any other disconnection event (i.e device disconnected).
%
%\textbf{DeviceAvailable: }
%\texttt{DeviceController} stays in this state until \texttt{Data-Manager}'s mSelectedTaskAvailable event fires (Device connected, no task selected). Then it switches to either \textit{MoveToTask} or \textit{RandomWalk} state depending on the selected task.  \texttt{DeviceController}  returns to this state from \textit{RandomWalk}, \textit{MoveToTask} or \textit{AtTask} states after a pre-set task time-out period has elapsed.  In that case it triggers the \texttt{DataManager}'s \texttt{mTaskTimedOut} event.
%
%\textbf{RandomWalk: }
%Robot can random walk in two cases: 1) when \texttt{TaskSelector} selects this random-walk task or 2) when the robot can not get its pose information for a moment. The latter helps the pose tracker to recover the robot-pose from a crowd of robots. Robot continues to do random-walk until it's task time-out period elapses or it's pose remains unavailable from the pose tracker (i.e. random-walk pending).
%
%\textbf{MoveToTask: }
%In this state, robot takes step-by-step navigation approach to reach a task boundary. Until the robot reaches the task boundary (Away from task), in every navigation-step it adjusts its heading to task based on both  robot and task pose information and then makes a fixed-time translation movement. In worse cases, when time-out happens early before reaching a task  \texttt{DeviceController} switches from this state to \textit{DeviceAvailable} state. However, if the same task is selected immediately, it is more likely that it will go to \textit{AtTask} state in next few steps.
%
%\textbf{AtTask: }
%In this state  \texttt{DeviceController} discovers itself neat the task and normally until task time-out happens (i.e. task pending) it stays at this state.

In order to realize LPCM strategy, in the implementation of RCC we have added three new D-Bus signal interfaces. They are briefly specified in Table \ref{table:dbus-signals}. Our base implementation of RCC's task-allocation (i.e. \texttt{TaskSelector}) is almost unchanged in this local implementation. The only thing we need to extend is the D-Bus signal reception and emission interfaces that catches the above signals and put the signal payload in \texttt{DataManager}. For the sake of simplicity, we have merges the perceived \texttt{TaskInfo} with communicated \texttt{LocalTaskInfo} into one so that \texttt{TaskAllocator} always gets all available task information. We have not made any major change in other modules of RCC, i.e. \texttt{DeviceController}. The full Python implementation of this RCC is available for download from the GitHub repository\footnote{http://github.com/roboshepherd/EpuckDistributedClient }.
%---------------------------
\subsubsection{TPS modules}
In our GSNC strategy based implementation of TPS periodically broadcasts \texttt{TaskInfo} signals to all robots using similar D-Bus signal emitting and listening modules. Task information has been updated by a separate Python module following the TPS algorithm described before. In the local version, TPS only emits \texttt{TaskInfo} signal when a robot is within a task's perception range, $r_{task}$ based-on the \texttt{TaskNeighbour} signal from SwisTrack. For this additional interface, we have extended D-Bus \texttt{SignalListener} to catch this additional D-Bus signal.  No major changes are done in the other parts of TPS implementation. The full Python implementation of TPS is available for download from the authors' GitHub centralized\footnote{http://github.com/roboshepherd/CentralizedTaskServer}
and distribued \footnote{http://github.com/roboshepherd/DitributedTaskServer} repositories.

%================================================================
\section{Results}
\label{sec:results}
In this section we have presented our experimental results. We ran those experiments for about 40 minutes duration.  They are averaged over five iterations for Series A and B experiments and three iterations for Series C and D experiments. 
%%-------------------------------------------------
\subsection{Shop-floor work-load history}
In our experiments we have defined shop-floor work-load in terms of task urgencies. For example, Eq. \ref{eqn:task-urgency-prod-init} shows how we have calculated initial production work-load of our manufacturing shop-floor scenario. Fig. \ref{fig:raw-urgencies}  show the dynamic changes in task-urgencies for the single iteration of each experiment. The fluctuations in these plots are resulted from the different levels of task-performance of our robots. In case of Series D, we can see that an unattended task, \textit{Task4}, was not served by any robot for a long period and later it was picked up by some of the robots. 
%%
\begin{figure*}
\begin{minipage}[t]{0.48\linewidth}
\centering
\subfloat[Series A]
{\includegraphics[width=0.7\linewidth, angle=0]
{images/SA-PlotUrgencyLog-2010Apr30-095755.eps}}
\newline
\subfloat[Series B]
{\includegraphics[width=0.7\linewidth, angle=0]
{images/SB-PlotUrgencyLog-2010May10-115549.eps}}
\newline
\subfloat[Series C]
{\includegraphics[width=0.7\linewidth, angle=0]
{images/SC-PlotUrgencyLog-2010Feb15-171017.eps}}
\newline
\subfloat[Series D]
{\includegraphics[width=0.7\linewidth, angle=0]
{images/SD-PlotUrgencyLog-2010Feb17-112141.eps}}
\newline
\caption{Changes in task-urgencies.}
\label{fig:raw-urgencies}
%\end{figure}
\end{minipage}
\begin{minipage}[t]{0.48\linewidth}
%\begin{figure}
\centering
\subfloat[Series A]
{\includegraphics[width=0.65\linewidth, angle=0]
{images/SA-8robots2tasks-TaskUrgencyStat.eps}}
\newline
\subfloat[Series B]
{\includegraphics[width=0.65\linewidth, angle=0]
{images/SB-TaskUrgencyStat.eps}}
\newline
\subfloat[Series C]
{\includegraphics[width=0.65\linewidth, angle=0]
{images/SC-TaskUrgencyStat.eps}}
\newline
\subfloat[Series D]
{\includegraphics[width=0.65\linewidth, angle=0]
{images/SD-TaskUrgencyStat.eps}}
\newline
\caption{Shop-floor workload change history.}
\label{fig:urgency-stat}
\end{minipage}
\end{figure*}
%%
In order to measure the task-related work-loads on our system we have summed up the changes in all task-urgencies over time. We call this as {\em shop-floor work-load history} and formalized as follows. Let $ \phi_{j, q}$ be the urgency of a task $j$ at $q^{th}$ step and $\phi_{j, q+1}$ be the task urgency of $(q+1)^{th}$ step. We can calculate the sum of changes in urgencies of all $M$ tasks at $(q+1)^{th}$ step:
\begin{equation} 
\Delta \Phi_{j, q+1} = \sum_{j=1}^{M} (\phi_{j, q+1} - \phi_{j, q})
\label{eqn:Delta-Phi}
\end{equation}
Fig. \ref{fig:urgency-stat} shows the dynamic shop-floor workload for all four series of experiments. From these plots, we can see that initially the sum of changes of task urgencies (shop-floor workload) is going towards negative direction. This implies that tasks are being served by a high number of robots. 
%%
%%
%%----------------------------------------------------------------
\subsection{Ratio of active workers}
%%
\begin{figure}
\begin{minipage}[t]{0.48\linewidth}
\centering
\subfloat[Series A]
{\includegraphics[width=0.65\linewidth, angle=0]
{images/SA-Plasticity-8robots2tasks.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series B]
{\includegraphics[width=0.65\linewidth, angle=0]
{images/SB-WorkerRatio.eps}}
\newline
\subfloat[Series C]
{\includegraphics[width=0.65\linewidth, angle=0]
{images/SC-Local50cm-Plasticity.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series D]
{\includegraphics[width=0.65\linewidth, angle=0]
{images/SD-Local1m-Plasticity.eps}}
\newline
\caption{Self-organized allocation of robots.} 
\label{fig:worker-stat}
%\end{figure}
\end{minipage}
\begin{minipage}[t]{0.48\linewidth}
%\begin{figure}
\centering
\subfloat[Series A]
{\includegraphics[width=0.7\linewidth, angle=0]
{images/SA-8robots-DeltaTranslationStat.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series B]
{\includegraphics[width=0.7\linewidth, angle=0]
{images/SB-DeltaTranslationStat.eps}}
\newline
\subfloat[Series C]
{\includegraphics[width=0.6\linewidth, angle=0]
{images/SC-DeltaTranslationStat.eps}}
\newline
\subfloat[Series D]
{\includegraphics[width=0.7\linewidth, angle=0]
{images/SD-DeltaTranslationStat.eps}}
\newline 
\caption{Sum of the translations of robots}
\label{fig:translation-stat}
\end{minipage}
\end{figure}
%%
From Fig. \ref{fig:worker-stat}, we can  see that in production stage, when work-load is high, many robots are active in tasks. Here active workers ratio is the ratio of those robots that work on tasks to the total number of robots $N$ of a particular experiment.   Here we can see that this ratio varies according to the shop-floor work-load changes.
%%-------------------------------------------------------------
\subsection{Shop-task performance}
%%
%\begin{figure}
%\begin{centering}
%\subfloat[APCD]
%{\includegraphics[width=0.7\linewidth, angle=0]
%{images/apcd.eps}}
%%\hspace{0.2cm}
%\newline
%\subfloat[APMW]
%{\includegraphics[width=0.7\linewidth, angle=0]
%{images/apmw.eps}}
%\newline
%\caption{Performance of manufacturing shop-floor tasks.} 
%\end{centering}
%\label{fig:mfg-stat} 
%\end{figure}
%%
In our manufacturing shop-floor scenario, we have calculated the APCD and APMW as shown in Fig. \ref{fig:mfg-stat}. For Series A we have got  average production completion time 111 time-steps (555s) where sample size is (5 x 2) = 10 tasks, SD = 10 time-steps (50s). According to Eq. \ref{eqn:min-pmm}, our theoretical minimum production completion time is 50 time-steps (250s) assuming the non-stop task performance of all 8 robots with an initial task urgency of 0.5 for 2 tasks and task urgency decrease rate $\Delta \Phi_{DEC }$ = 0.0025 per robot per time-step.  Hence, Eq. \ref{eqn:appd} gives us APCD, $\zeta$ = 1.22 which means that in Series A experiments, it took 1.22 times more time (305s) than the estimated minimum production completion time (250s). For Series B, we have got average production completion time 165 time-steps (825s) where sample size is (5 x 4) = 20 tasks, SD = 72 time-steps (360s).  Hence, Eq. \ref{eqn:appd} gives us APCD, $\zeta$ = 2.3. For Series C we have got average production completion time 121 time-steps (605s) with SD = 36 time-steps (180s). For Series D,  average production completion time is 123 time-steps (615s) with SD = 40 time-steps (200s). According to Eq. \ref{eqn:min-pmm}, our theoretical minimum production completion time is 50 time-steps (250s).  The values of APCD are as follows. For Series C, $\zeta$ = 1.42 and for Series D, $\zeta$ = 1.46. For both series of experiments APCD values are very close.

For APMW, Series A experiments give us an average time length of 369 time-steps (1845s).  In this period we have calculated APMW and it is 1 time-step with SD = 1 time-step (5s) and $\Delta \Phi_{INC}$ = 0.005 per task per time-step. This shows a very low APMW ($\chi$ = 0.000235) implying a very high robustness of our system. For Series B experiments, from the average 315 time-steps (1575s) maintenance activity of our robots per experiment run, we have got APMW, $\chi$ = 0.012756 which corresponds to the pending work of 3 time-steps (15s) where SD = 13 time-steps (65s). This also tells us the robust task performance of our robots which can return to an abandoned task within a minute or so. The APMW of Series C experiments give us an average time length of 359 time-steps (1795s). In this period we calculated APMW and it is 5 time-steps with SD = 17 time-steps and $\chi$ = 0.023420. For Series D experiments, from the average 357 time-steps (1575s) of maintenance activity of our robots per experiment run, we have got APMW, $\chi$ = 0.005359 which corresponds to the pending work of 2 time-steps (10s) where SD = 7 time-steps.
%%-------------------------------------------------
\subsection{Task specializations}
We have measured the task-specialization of the robots based-on their peak value of sensitization. This maximum value represents how long a robot has repeatedly been selecting a particular task. Since tasks are homogeneous we have considered the maximum sensitization value of a robot among all tasks during an experiment run. This value is then averaged for all robots using the following  equation. 
%%
\begin{equation}
K^G_{avg} = \frac{1}{N}\sum_{i=1}^{N} \max_{j=1}^M\left ( k^i_{j, q} \right ) 
\label{eqn:K-G}
\end{equation}
%%
If a robot $r_i$ has the peak sensitization value $k^i_j$ on task $j$ ($j \in M$)  at $q^{th}$ time-step, Eq. \ref{eqn:K-G} calculates the average of the peak task-specialization values of all robots for a certain iteration of our experiments. We have also averaged the time-step values ($q$) taken to reach those peak values for all robots using the following equation.
%%
\begin{equation}
Q^G_{avg}= \frac{1}{N}\sum_{i=1}^{N} q^i_{k=k_{max}}
\label{eqn:Q-G}
\end{equation}
In Eq. \ref{eqn:Q-G}, $q^i_{k=k_{max}}$ represents the time-step of robot $r_i$  where its sensitization value $k$ reaches the peak $k_{max}$ as discussed above. By averaging this peak time-step values of all robots we can have an overall idea of how many task-execution cycles are spent to reach the maximum task-specialization value $K^G_{avg}$.
%% S-A
%\begin{table}
%\centering
%\caption{Peak task-sensitization values of robots in a Series A experiment.}
%% 30Apr expt.
%\begin{tabular}{|c|c|c|c|}
%\hline \textbf{Robot ID} & \textbf{Maximum k} & \textbf{At time-step (q)} & \textbf{Task} \\ 
%\hline 1 & 0.54 & 64 & Task1\\
%\hline 4 & 0.32 & 14 & ,,\\
%\hline 5 & 0.27 & 11 & ,,\\
%%%
%\hline 3 & 0.47 & 63 & Task2\\
%\hline 2 & 0.46 & 64 & ,,\\
%\hline 6 & 0.20 & 10 & ,,\\
%\hline 7 & 0.18 & 4 & ,,\\
%\hline 8 & 0.15 & 3 & ,,\\
%\hline 
%\end{tabular} 
%\label{table:K-G-SA}
%\end{table}
%%% S - B
%\begin{table}
%\centering
%\caption{Peak task-sensitization values of robots in a Series B experiment.}
%\begin{tabular}{|c|c|c|c|}
%% Apr 18 Feb-3 expt
%\hline \textbf{Robot ID} & \textbf{Maximum k} & \textbf{At time-step (q)} & \textbf{Task} \\
%\hline 24 & 0.41 & 29 & Task1\\
%\hline 13 & 0.31 & 19 & ,,\\
%\hline 16 & 0.18 & 4 & ,,\\
%%% 
%\hline 1 & 0.64 & 66 & Task2\\
%\hline 35 & 0.34 & 12 & ,,\\
%\hline 5 & 0.28 & 14 & ,,\\
%\hline 22 & 0.18 & 20 & ,,\\
%\hline 17 & 0.16 & 6 & ,,\\
%\hline 3 & 0.14 & 12 & ,,\\
%%%
%\hline 9 & 0.68 & 66 & Task3\\
%\hline 6 & 0.43 & 71 & ,,\\
%\hline 15 & 0.19 & 4 & ,,\\
%\hline 14 & 0.15 & 4 & ,,\\
%\hline 31 & 0.14 & 4 & ,,\\
%%%
%\hline 19 & 0.22 & 12 & Task4\\
%\hline 12 & 0.16 & 10 & ,,\\
%\hline 
%\end{tabular} 
%\label{table:K-G-SB}
%\end{table}
Table \ref{table:K-G-SA} and Table \ref{table:K-G-SB} show the peak sensitization values of Series A and Series B experiments respectively.  Based on Eq. \ref{eqn:K-G} and Eq. \ref{eqn:Q-G}, we have got the peak task-sensitization $K^G_{avg} 
$ values: 0.40 (SD=0.08)  and 0.30 (SD=0.03), and their respective time-step $Q^G_{avg}$ values: 38 (SD=13) and 18 (SD=5) time-step.  They are shown in Fig. \ref{fig:task-specialization}. Here we can see that the robots in Series A had higher chances of task-specialization than that of Series B experiments.
%%
%% Series C raw data
%\begin{table}
%\centering
%\caption{Peak task-sensitization values of robots in a Series C experiment.}
%% 16Feb-1 expt
%\begin{tabular}{|c|c|c|c|}
%\hline\textbf{ Robot ID} & \textbf{Maximum k} & \textbf{At time-step (q)} & \textbf{Task} \\
%\hline 16 & 1.00 & 52 & Task1\\
%\hline 12 & 0.58 & 24 & ,,\\  
%\hline 1 & 0.16 & 2 & ,,\\ 
%\hline 13 & 0.13 & 1 & ,,\\
%%%
%\hline 9 & 1.00 & 41 & Task2\\
%\hline 3 & 0.55 & 23 & ,,\\ 
%\hline 19 & 0.24 & 6 & ,,\\
%\hline 35 & 0.24 & 6 & ,,\\
%\hline 15 & 0.13 & 1 & ,,\\
%\hline 33 & 0.13 & 2 & ,,\\ 
%%%
%\hline 6 & 0.61 & 29 & Task3\\
%\hline 31 & 0.59 & 35 & ,,\\ 
%\hline 5 & 0.13 & 1 & ,,\\ 
%%%
%\hline 17 & 0.36 & 10 & Task4\\
%\hline 20 & 0.09 & 1 & ,,\\ 
%\hline 22 & 0.09 & 1 & ,,\\ 
% \hline 
%\end{tabular} 
%\label{table:K-Q-SC}
%\end{table}
%%% Series D
%\begin{table}
%\centering
%\caption{Peak task-sensitization values of robots in a Series D experiment.}
%%% 17 feb-1 expt
%\begin{tabular}{|c|c|c|c|}
%\hline\textbf{ Robot ID} & \textbf{Maximum k} & \textbf{At time-step (q)} & \textbf{Task} \\
%\hline 19 & 1.00 & 34 & Task1\\
%\hline 35 & 1.00 & 60 & ,,\\
%\hline 24 & 0.41 & 16 & ,,\\
%\hline 12 & 0.20 & 6 & ,,\\  
%%%
%\hline 1 & 1.00 & 41 & Task2\\
%\hline 31 & 1.00 & 47 & ,,\\
%\hline 22 & 0.40 & 10 & ,,\\
%\hline 9 & 0.38 & 12 & ,,\\
%\hline 15 & 0.16 & 2 & ,,\\
%\hline 33 & 0.13 & 1 & ,,\\ 
%%%   
%\hline 5 & 0.92 & 70 & Task3\\ 
%\hline 13 & 0.74 & 36 & ,,\\
%%% 
%\hline 17 & 0.76 & 62 & Task4\\ 
%\hline 6 & 0.22 & 4 & ,,\\ 
%\hline 3 & 0.13 & 2 & ,,\\
%\hline 16 & 0.13 & 1 & ,,\\ 
%\hline 
%\end{tabular}
%\label{table:K-Q-SD} 
%\end{table}
%%%
%\begin{figure}
%\centering
%\subfloat[Task-sensitization (K)]
%{\includegraphics[width=0.7\linewidth, angle=0]
%{images/K-Group.eps}}
%%\hspace{0.2cm}
%\newline
%\subfloat[Time-steps (Q)]
%{\includegraphics[width=0.7\linewidth, angle=0]
%{images/Q-Group.eps}}
%\newline
%\caption{ Overall task-specialization of robot groups based on Peak task-sensitization values.}
%\label{fig:task-specialization} 
%\end{figure}
%%
%% ------ Single robot----
%\begin{figure}
%\centering
%\includegraphics[width=\linewidth, angle=0]{images/TaskSpecialization-task3-10may-1.eps}
%\caption{Task specialization on Task3 for a Series B experiment.}
%\label{fig:k-single-task-SB} 
%\end{figure}
%%%
%Fig. \ref{fig:k-single-task-SB} shows us the task specialization of five robots on \textit{Task3} in a particular run of Series B experiment. This shows us how some of the robots can specialize (learn) and de-specialize (forget) tasks over time.
%%-------------------------------------------------
\subsection{Robot motions}
We have aggregated the changes in translation motion of all robots over time based on their travelled distances in Euclidean metric. Let $u_{i,q}$ and $u_{i,q+1}$ be the translations of a robot $i$ in two consecutive steps. If the difference between these two translations be $\delta u_{i}$, we can find the sum of changes of translations of all robots in $(q+1)^{th}$ step using the following equation.
\begin{equation}
\Delta U_{q+1} = \sum_{i=1}^{N} \delta u_{i, q+1} 
\label{eqn:Delta-Tr}
\end{equation}
%%
The sum of translations of robots from our experiments are plotted in Fig. \ref{fig:translation-stat}. In this plot we can see that robot translations also vary over varying task requirements of tasks.
%%%-------------------------------------------------
\subsection{Communication load}
%%% Communication load 
%%
\begin{figure}
\centering
\subfloat[Series A]
{\includegraphics[width=0.7\linewidth, angle=0]
{images/SA-8Robot-SignalingFreqStat.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series B]
{\includegraphics[width=0.7\linewidth, angle=0]
{images/SB-SignalingFreqStat.eps}}
\newline
\subfloat[Series C]
{\includegraphics[width=0.7\linewidth, angle=0]
{images/SC-Local-500cm-SignalingFreqStat.eps}}
%\hspace{0.2cm}
\newline
\subfloat[Series D]
{\includegraphics[width=0.7\linewidth, angle=0]
{images/SD-Local-1m-SignalingFreqStat.eps}}
\newline
\caption{Frequency of \texttt{TaskInfo} signalling of (a) and (b) by TPS and (c) and (d) by local peers.}
\label{fig:signal-frequency-stat}
\end{figure}
%%
%%%% Single robot- number of peers
\begin{figure}
\begin{centering}
\subfloat[Series C]{\includegraphics[width=0.7\linewidth]{images/Robot12-16feb-1-LocalSignals.eps}}
\newline
\subfloat[Series D]{\includegraphics[width=0.7\linewidth]{images/Robot12-17feb-3-LocalSignals.eps}}
\newline
\caption{\small \texttt{LoaclTaskInfo} (P2P) signals caught by Robot12 in (a) Series C and (b) Series D experiment}
\end{centering}
\label{fig:local-single-robot-signal}
\end{figure}
%%
Fig. \ref{fig:signal-frequency-stat} (a) and (b) shows the number of received \texttt{TaskInfo} signals by each robot in Series A and Series B experiments. Since the duration of each time-step is 50s long and TPS emits signal in every 2.5s, there is an average of 20 signals in each time-step. The overall P2P task information signals of both of these local modes are plotted in Fig. \ref{fig:signal-frequency-stat} (c) and (d). As an example of P2P signal reception of a robot,  Fig. \ref{fig:local-single-robot-signal} show the number of received signals by \textit{Robot12} in two local experiments. It states the relative difference of peers over time in two different cases.
%===================================================================
\section{Discussions}
\label{sec:discuss}
\subsection{Self-regulated MRTA}
From our experimental results, we have noted several aspects of self-regulated MRTA that expose the effectiveness of AFM. As we have pointed out that this self-regulated MRTA, as observed in biological and human social systems, needs to satisfy several important characteristics, particularly plasticity and task-specialization. In addition to satisfying those basic qualities, AFM has demonstrated many other aspects. Our self-regulated robots, driven by AFM, effectively handle the dynamic work-load in our manufacturing shop-floor. They can dynamically support the need to work on demanding tasks, if there any. The variations of active worker ratio shows this. 

From the self-organized worker allocations of AFM, it is clear to us that although in larger system (Series B) the degree of variations of active-worker ratio can show us significantly unpredictable patterns, nevertheless the self-regulated rules drive the robots to respond to the dynamic needs of the system. This means that AFM can sufficiently produce the plasticity of DOL in order to meet the dynamic work-load of the system.
%%
\subsection{Learning and forgetting} 
From the individual and group-level task-specialization, we can see that robots can maintain both task-specialization and flexibility. In a self-organized system, it is very common that only a few individuals specialize on tasks and others generally do not. From two sample data sets provided in Table \ref{table:K-G-SA} and Table \ref{table:K-G-SB}, we can see that in particular runs of Series A and Series B experiments, task-sensitization values of  only 2-3 robots reach above the group-level average score. Thus in both types of experiments, robots exhibit similar task-specialization behaviours. 
%%
\subsection{Concurrency and robustness}
As a consequence of fewer robots specializing in tasks, we can also see that robots can concurrently  consider different tasks without being biased to a particular task all the time. Our experiments also show us the robust MRTA as in case of  both high and low work-loads present in the system. This is evident from the manufacturing shop-floor task performance during PMM and MOM. For example,  in case of Series B experiments APMW was 13 time-steps (65s) which corresponded  to pending work-load of 0.065 unit for a single robot. Thus, on an average, before the work-load exceeded by about 13 percent of initial work-load, robots were able to respond to  a task.
%%
\subsection{Communication load}
In GSNC strategy based experiments we used a centralized communication system (source of attractive fields) that serves the robots with necessary task-perception information.  Our centralized communication system has the advantage of minimising the communication load and the disadvantage of a single point of failure as well as a single point of load. Under LSLC strategy based implementation, we present how the task perception can be decentralized by P2P communications among RCCs.
%%
\subsection{Scaling-up}
We have observed the effect of scaling-up the robot team size. The system size of Series B is double of that of Series A in terms of robots, tasks and experiment arena. Keeping a fixed ratio of robot-to-task and task-to-arena we have intended to see the scaling effects in our experiments. Here we see that both systems can show sufficient self-regulated DOL, but task-performance of both systems varies significantly. For example, the value of APCD in Series B is higher by 1.08. This means that performance  is decreased in Series B experiments despite having the resources in same proportion in both systems. This occurs partly due to the greater stochastic effects found in task-allocation in a larger system, e.g. presence of more tasks produce higher stochastic behaviours in robot's task selection.

Similarly we can see that in larger system robots have less chances to specialize on tasks, as the Series B experiments show us that the overall average task-specialization of the group $K^G_{avg}$ is lower by 0.10 and it lasts for significantly less time (the difference of $Q^G_{avg}$  of both systems is 20 time-steps). Thus, in a large group, robots are more likely to switch among tasks more frequently and this produces more translation motions which cost more energy (e.g. battery power) in task-performance.
%%
\subsection{Comparisons between GSNC and LSLC strategies} 
Results from Series C and Series D experiments show us many similarities and differences with respect to the results of Series A and Series B experiments. Both Series C and Series D experiments show similar APCD values: 1.42 and 1.46 respectively, which are significantly less than Series B experiment result (APCD = 2.3) and are close to Series A experiment result (APCD = 1.22). This means that for large group, task-performance  is efficient under LSLC strategy (Series C and Series D) comparing with their GSNC counterpart (Series B).

Besides, in terms of task-specialization, the overall task-specialization of group in Series C ($K^G_{avg}$ = 0.4) is  closer to that of Series A experiments ($K^G_{avg}$ = 0.39) and interestingly, the value of  Series D ($K^G_{avg}$ = 0.27) is  much closer to that of Series B experiments ($K^G_{avg}$ = 0.30). So task-specialization in large group under LSLC strategy shows higher performance than their GSNC counter part. Besides task-specialization happens much faster under LSLC strategy as we can see that the average time to reach peak sensitization values  of the group,  $Q^G_{avg}$ in Series C is lower than that of Series A values by 25 time-steps.

\begin{table}
\begin{center}
\caption{Sum of translations of robots in our experiments.}
\begin{tabular}{|c|c|c|}
\hline \textbf{Series} & \textbf{Average translation (m)} & \textbf{SD} \\ 
\hline A & 2.631 & 0.804\\ 
\hline B & 13.882 & 3.099\\
\hline C & 4.907 & 1.678\\
\hline D & 4.854 & 1.592\\
\hline
\end{tabular}
\label{table:motion-cmp} 
\end{center}
\end{table}
%%
From the robot motion profiles found in all four series of experiments, we have found that under LSLC strategy, robot translations have been reduced significantly. Table \ref{table:motion-cmp} summarizes the average translations done by robots in all four series of experiments. From this table we can see than Series C and Series D show about 2.8 times less translation than that in Series B experiments. The translation of 16 robots in Series C and Series D experiments are approximately double (1.89 times) than that of Series A experiments with 8 robots.  Thus the energy-efficiency under LSLC strategy seems to be higher  than that under GSNC strategy.

From the above results we can see that large group of robots achieve better MRTA under LSLC strategy. The local sensing of tasks prevents them to attend a far-reaching task which may be more common under global sensing strategy. However, as we have seen in Fig. \ref{fig:raw-urgencies} some tasks can be left unattended for a long period of time due to the failure to discover it by any robot. For that reason we see that the values of APMW is slightly higher under LSLC strategy. But this trade-off is worth as LSLC strategy provides superior self-regulated MRTA in terms of task-performance, task-specialization and energy-efficiency. 
%====================================================================
\section{Conclusion and future works}
\label{sec:conc}
The benefits of deploying a large number of robots in dynamic multi-tasking environment can not be fully realized without adopting an effective communication and sensing strategy for a given multi-robot system. This study has focused on comparing two bio-inspired  communication and sensing strategies in producing self-regulated MRTA by an interdisciplinary model of DOL, AFM. Under the GSNC strategy, AFM has produced the desired self-regulated MRTA among a group of 8 and 16 robots. This gives us the evidence that AFM can successfully solve the MRTA issue of a complex multi-tasking environment like a manufacturing shop-floor. Under the LSLC strategy, AFM can also produce the desired self-regulated MRTA for 16 robots with different communication and sensing ranges.

From our comparative results, we note that for large group of robots,  degradation in  task-performance and task-specialization of robots are likely to occur  under GSNC strategy that relies upon a centralized communication system. Thus GSNC strategy can give us better performance when the number of tasks and robots are relatively small. This confirms us the assertions made by some biologists that self-regulated DOL among small group of individuals can happen without any significant amount of local communications and interactions. However, our findings suggest that task-specialization can still be beneficial among the individuals of a small group which contradicts the claim that small groups only posses the generalist workers, but not the specialists.

On the other hand, LSLC strategy is more suitable for large group of individuals that are likely to be unable to perform global sensing and global communications with all individuals of the group. The design of communication and sensing range has still remained as a critical research issue. However, our results suggest that the idea of maximizing information gain is not appropriate under a stochastic task-allocation process. Here more information tends to cause more task-switching behaviours that lowers the level of task-specialization of the group. This might not be the case under a deterministic task-allocation scheme where more information may lead to better and optimum allocations in  a small group of individuals. Nevertheless, despite having the limited communication and sensing range, LSLC strategy has helped the robots to produce comparatively better task-allocation with increased task-specialization and significantly reduced motions or savings in energy consumption.
%============================================
\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
\bibliography{IEEEabrv,SarkerDahl2011}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
%\begin{thebibliography}{1}
%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
%\end{thebibliography}
% biography section
% 
% If you have an EPS/PDF photo (graphicx package needed) extra braces are
% needed around the contents of the optional argument to biography to prevent
% the LaTeX parser from getting confused when it sees the complicated
% \includegraphics command within an optional argument. (You could create
% your own custom macro containing the \includegraphics command to make things
% simpler here.)
%\begin{biography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{mshell}}]{Michael Shell}
%% or if you just want to reserve a space for a photo:
%
%\begin{IEEEbiography}{Michael Shell}
%Biography text here.
%\end{IEEEbiography}
%
%% if you will not have a photo at all:
%\begin{IEEEbiographynophoto}{John Doe}
%Biography text here.
%\end{IEEEbiographynophoto}
%
%% insert where needed to balance the two columns on the last page with
%% biographies
%%\newpage
%
%\begin{IEEEbiographynophoto}{Jane Doe}
%Biography text here.
%\end{IEEEbiographynophoto}
% You can push biographies down or up by placing
% a \vfill before or after them. The appropriate
% use of \vfill depends on what kind of text is
% on the last page and whether or not the columns
% are being equalized.
%\vfill
% Can be used to pull up biographies so that the bottom of the last one
% is flush with the other column.
%\enlargethispage{-5in}
% that's all folks
\end{document}
